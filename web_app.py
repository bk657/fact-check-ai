import streamlit as st
from supabase import create_client, Client
import re
import requests
import time
import random
import math
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from openai import OpenAI
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
import altair as alt
import json
from bs4 import BeautifulSoup

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° v99.6", layout="wide", page_icon="ğŸ›¡ï¸")

if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False
if "debug_logs" not in st.session_state:
    st.session_state["debug_logs"] = []

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    GOOGLE_API_KEY_A = st.secrets["GOOGLE_API_KEY_A"]
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
except Exception as e:
    st.error(f"âŒ í•„ìˆ˜ í‚¤ ì„¤ì • ëˆ„ë½: {e}")
    st.stop()

# Mistral í´ë¼ì´ì–¸íŠ¸ (Key B ì „ìš©)
mistral_client = OpenAI(api_key=MISTRAL_API_KEY, base_url="https://api.mistral.ai/v1")

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase = init_supabase()

# --- [2. ê¸€ë¡œë²Œ ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹°] ---
STATIC_TRUTH_CORPUS = ["ë°•ë‚˜ë˜ ìœ„ì¥ì „ì… ë¬´í˜ì˜", "ì„ì˜ì›… ì•”í‘œ ëŒ€ì‘", "ì •í¬ì› ì €ì†ë…¸í™”", "ëŒ€ì „ ì¶©ë‚¨ í†µí•©", "ì„ ê±° ì¶œë§ˆ ì„ ì–¸"]
STATIC_FAKE_CORPUS = ["ì¶©ê²© í­ë¡œ ê²½ì•…", "ê¸´ê¸‰ ì†ë³´ ì†Œë¦„", "ì¶©ê²© ë°œì–¸ ë…¼ë€", "êµ¬ì† ì˜ì¥ ë°œë¶€", "ì˜ìƒ ìœ ì¶œ", "ê³„ì‹œ ì˜ˆì–¸", "ì‚¬í˜• ì§‘í–‰", "ìœ„ë…ì„¤"]
CRITICAL_STATE_KEYWORDS = ['ë³„ê±°', 'ì´í˜¼', 'íŒŒê²½', 'ì‚¬ë§', 'ìœ„ë…', 'êµ¬ì†', 'ì²´í¬', 'ì‹¤í˜•', 'ë¶ˆí™”', 'í­ë¡œ', 'ì¶©ê²©', 'ë…¼ë€', 'ì¤‘íƒœ', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'íŒŒì‚°', 'ë¹šë”ë¯¸', 'ì „ê³¼', 'ê°ì˜¥', 'ê°„ì²©']
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']
WEIGHT_ALGO = 0.6
WEIGHT_AI = 0.4

def parse_ai_json(text):
    try:
        parsed = json.loads(text)
    except:
        try:
            text = re.sub(r'```json\s*', '', text).replace('```', '')
            match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
            if match: 
                parsed = json.loads(match.group(1))
                return parsed[0] if isinstance(parsed, list) else parsed
        except: pass
    return None

def safe_int_convert(val, default=50):
    try:
        if isinstance(val, dict): val = list(val.values())[0]
        return int(float(val))
    except: return default

def extract_video_id(url):
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return match.group(1) if match else None

# --- [3. ëª¨ë¸ ì—”ì§„ ì„¸íŒ…] ---

# [Key A] Gemini ê¸°ì¡´ ë¡œì§ ìœ ì§€
def get_gemini_search_keywords(title, transcript):
    genai.configure(api_key=GOOGLE_API_KEY_A)
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"Role: Fact-Check Investigator. [Input] Title: {title}, Transcript: {transcript[:15000]}. [Task] Extract ONE Korean search query (2-4 words). Output ONLY the string."
    try:
        response = model.generate_content(prompt)
        st.session_state["debug_logs"].append(f"âœ… Key A (Gemini) Keyword Extracted")
        return response.text.strip()
    except Exception as e:
        st.session_state["debug_logs"].append(f"âŒ Key A Failed: {e}")
        return title

# [Key B] Mistral Judge ì „ìš©
def call_mistral_judge(prompt):
    try:
        response = mistral_client.chat.completions.create(
            model="mistral-large-latest",
            messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íŒ©íŠ¸ì²´í¬ íŒì‚¬ì…ë‹ˆë‹¤. ëª¨ë“  ë¶„ì„ ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                      {"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.1
        )
        st.session_state["debug_logs"].append("âœ… Key B (Mistral) Verdict Success")
        return response.choices[0].message.content
    except Exception as e:
        st.session_state["debug_logs"].append(f"âŒ Key B Mistral Error: {e}")
        return None

# --- [4. ë¶„ì„ ì—”ì§„ (ì¦ê±° ìˆ˜ì§‘ ë¡œì§ ë³µêµ¬)] ---

class VectorEngine:
    def __init__(self):
        self.vocab = set()
        self.truth_vectors = []
        self.fake_vectors = []
    def tokenize(self, text): return re.findall(r'[ê°€-í£]{2,}', text)
    def train(self, truth, fake):
        for t in truth + fake: self.vocab.update(self.tokenize(t))
        self.vocab = sorted(list(self.vocab))
        self.truth_vectors = [self.text_to_vector(t) for t in truth]
        self.fake_vectors = [self.text_to_vector(t) for t in fake]
    def text_to_vector(self, text, vocabulary=None):
        target_vocab = vocabulary if vocabulary else self.vocab
        c = Counter(self.tokenize(text))
        return [c[w] for w in target_vocab]
    def cosine_similarity(self, v1, v2):
        dot = sum(a*b for a,b in zip(v1,v2))
        mag = math.sqrt(sum(a*a for a in v1)) * math.sqrt(sum(b*b for b in v2))
        return dot/mag if mag>0 else 0
    def analyze_position(self, query):
        if not self.vocab: return 0, 0
        qv = self.text_to_vector(query)
        mt = max([self.cosine_similarity(qv, v) for v in self.truth_vectors] or [0])
        mf = max([self.cosine_similarity(qv, v) for v in self.fake_vectors] or [0])
        return mt, mf

vector_engine = VectorEngine()

def fetch_comments_via_api(video_id):
    try:
        url = "https://www.googleapis.com/youtube/v3/commentThreads"
        res = requests.get(url, params={'part': 'snippet', 'videoId': video_id, 'key': YOUTUBE_API_KEY, 'maxResults': 50})
        if res.status_code == 200:
            items = [i['snippet']['topLevelComment']['snippet']['textDisplay'] for i in res.json().get('items', [])]
            return items, "Success"
    except: pass
    return [], "Fail"

def analyze_comment_relevance(comments, context_text):
    if not comments: return [], 0, "ë¶„ì„ ë¶ˆê°€"
    all_cmt_text = " ".join(comments)
    tokens = [re.sub(r'[^ê°€-í£]', '', w) for w in re.findall(r'[ê°€-í£]{2,}', all_cmt_text)]
    top = Counter(tokens).most_common(5)
    ctx_tokens = set(re.findall(r'[ê°€-í£]{2,}', context_text))
    match = sum(1 for w, c in top if w in ctx_tokens)
    score = int(match/len(top)*100) if top else 0
    msg = "âœ… ì£¼ì œ ì§‘ì¤‘" if score >= 60 else "âš ï¸ ì¼ë¶€ ê´€ë ¨" if score >= 20 else "âŒ ë¬´ê´€"
    return [f"{w}({c})" for w, c in top], score, msg

def check_red_flags(comments):
    keywords = ['ê°€ì§œ', 'ì£¼ì‘', 'ì‚¬ê¸°', 'í—ˆìœ„', 'ì„ ë™', 'ê±°ì§“']
    detected = [k for c in comments for k in keywords if k in c]
    return len(detected), list(set(detected))

def count_sensational_words(text):
    return sum(text.count(w) for w in ['ì¶©ê²©', 'ê²½ì•…', 'ì‹¤ì²´', 'í­ë¡œ', 'ì†ë³´', 'ê¸´ê¸‰', 'ë‹¨ë…'])

# --- [5. UI ì»´í¬ë„ŒíŠ¸ (ë””ìì¸ ë³µêµ¬)] ---

def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border: 1px solid #e0e0e0; border-radius: 8px; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; padding: 12px; text-align: left; } table.score-table td { padding: 12px; border-bottom: 1px solid #f0f0f0; } .badge { padding: 4px 8px; border-radius: 6px; font-weight: 700; font-size: 11px; display: inline-block; } .badge-danger { background-color: #ffebee; color: #d32f2f; } .badge-success { background-color: #e8f5e9; color: #2e7d32; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            score_num = int(score)
            badge = f'<span class="badge badge-danger">+{score_num}</span>' if score_num > 0 else f'<span class="badge badge-success">{score_num}</span>' if score_num < 0 else "0"
        except: badge = str(score)
        rows += f"<tr><td>{item}<br><small style='color:#888;'>{note}</small></td><td style='text-align: right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª©</th><th style='text-align: right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def colored_progress_bar(label, percent, color):
    st.markdown(f"""<div style="margin-bottom: 10px;"><div style="display: flex; justify-content: space-between; margin-bottom: 3px;"><span style="font-size: 13px; font-weight: 600; color: #555;">{label}</span><span style="font-size: 13px; font-weight: 700; color: {color};">{round(percent * 100, 1)}%</span></div><div style="background-color: #eee; border-radius: 5px; height: 8px; width: 100%;"><div style="background-color: {color}; height: 8px; width: {percent * 100}%; border-radius: 5px;"></div></div></div>""", unsafe_allow_html=True)

def render_intelligence_distribution(current_prob):
    try:
        res = supabase.table("analysis_history").select("fake_prob").execute()
        if not res.data: return
        df = pd.DataFrame(res.data)
        base = alt.Chart(df).transform_density('fake_prob', as_=['fake_prob', 'density'], extent=[0, 100], bandwidth=5).mark_area(opacity=0.3, color='#888').encode(x=alt.X('fake_prob:Q', title='ê°€ì§œë‰´ìŠ¤ í™•ë¥  ë¶„í¬'), y=alt.Y('density:Q', title='ë°ì´í„° ë°€ë„'))
        rule = alt.Chart(pd.DataFrame({'x': [current_prob]})).mark_rule(color='blue', size=3).encode(x='x')
        st.altair_chart(base + rule, use_container_width=True)
    except: pass

# --- [6. ë©”ì¸ ë¡œì§] ---

def run_forensic_main(url):
    st.session_state["debug_logs"] = []
    vid = extract_video_id(url)
    if not vid: return st.error("URL ì˜¤ë¥˜")

    # DB í•™ìŠµ
    res_t = supabase.table("analysis_history").select("video_title").lt("fake_prob", 40).execute()
    res_f = supabase.table("analysis_history").select("video_title").gt("fake_prob", 60).execute()
    dt, df = [r['video_title'] for r in res_t.data], [r['video_title'] for r in res_f.data]
    vector_engine.train(STATIC_TRUTH_CORPUS + dt, STATIC_FAKE_CORPUS + df)
    db_count = len(dt) + len(df)

    # ìºì‹œ ì²´í¬
    cached_res = supabase.table("analysis_history").select("*").ilike("video_url", f"%{vid}%").order("id", desc=True).limit(1).execute()
    if cached_res.data:
        c = cached_res.data[0]
        try:
            d = json.loads(c.get('detail_json', '{}'))
            render_report_full_ui(c['fake_prob'], db_count, c['video_title'], c['channel_name'], d, is_cached=True)
            return
        except: pass

    my_bar = st.progress(0, text="ë¶„ì„ ì‹œì‘...")
    with yt_dlp.YoutubeDL({'quiet': True, 'skip_download': True}) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            title, uploader, desc = info.get('title',''), info.get('uploader',''), info.get('description','')
            tags = info.get('tags', [])
            
            # [1ë‹¨ê³„] ë°ì´í„° ìˆ˜ì§‘ (API ê¸°ë°˜)
            my_bar.progress(10, "1ë‹¨ê³„: ìë§‰ ë° ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...")
            subs = info.get('subtitles') or {}
            auto = info.get('automatic_captions') or {}
            merged = {**subs, **auto}
            full_text = desc
            if 'ko' in merged:
                for f in merged['ko']:
                    if f['ext'] == 'vtt':
                        res = requests.get(f['url'])
                        full_text = " ".join([l.strip() for l in res.text.splitlines() if l.strip() and '-->' not in l and '<' not in l])
                        break
            cmts, _ = fetch_comments_via_api(vid)

            # [2ë‹¨ê³„] AI ìˆ˜ì‚¬ê´€ (Key A ê¸°ì¡´ ë¡œì§)
            my_bar.progress(30, "2ë‹¨ê³„: AI ìˆ˜ì‚¬ê´€(Gemini) í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            query = get_gemini_search_keywords(title, full_text)
            
            # [3ë‹¨ê³„] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡°
            my_bar.progress(50, "3ë‹¨ê³„: ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡° ì§„í–‰ ì¤‘...")
            rss = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR"
            news_raw = requests.get(rss).text
            items = re.findall(r'<item>(.*?)</item>', news_raw, re.DOTALL)[:3]
            news_ev = []; max_match = 0
            for i in items:
                nt = re.search(r'<title>(.*?)</title>', i).group(1).replace("<![CDATA[", "").replace("]]>", "")
                nl = re.search(r'<link>(.*?)</link>', i).group(1)
                nd = re.search(r'<description>(.*?)</description>', i).group(1)
                
                # Mistralì„ ì´ìš©í•œ ë‰´ìŠ¤ ëŒ€ì¡°
                prompt_b = f"ë¹„êµ ë¶„ì„: ì˜ìƒ[{title}] vs ë‰´ìŠ¤[{nt}]. ì¼ì¹˜í•˜ë©´ 0-10, ë‹¤ë¥´ë©´ 90-100. JSON {{'score': int, 'reason': 'í•œê¸€ì´ìœ '}}"
                res_b = call_mistral_judge(prompt_b)
                p_b = parse_ai_json(res_b)
                s_b = safe_int_convert(p_b.get('score')) if p_b else 50
                if s_b > max_match: max_match = s_b
                news_ev.append({"ë‰´ìŠ¤ ì œëª©": nt, "ì¼ì¹˜ë„": f"{s_b}%", "ìµœì¢… ì ìˆ˜": s_b, "ë¶„ì„ ê·¼ê±°": p_b.get('reason','') if p_b else 'N/A', "ì›ë¬¸": nl})

            # ì•Œê³ ë¦¬ì¦˜ ìŠ¤ì½”ì–´ë§
            ts, fs = vector_engine.analyze_position(query + " " + title)
            t_impact, f_impact = int(ts*30)*-1, int(fs*30)
            news_penalty = -30 if max_match <= 20 else (30 if max_match >= 80 else 0)
            
            # ì¦ê±° 2, 3 ë¡œì§ ë³µêµ¬
            top_cmt_kw, rel_score, rel_msg = analyze_comment_relevance(cmts, title + " " + full_text)
            red_cnt, red_list = check_red_flags(cmts)
            agitation = count_sensational_words(title + full_text)

            # [4ë‹¨ê³„] AI íŒì‚¬ ìµœì¢… íŒê²° (Mistral)
            my_bar.progress(85, "4ë‹¨ê³„: AI íŒì‚¬(Mistral) ìµœì¢… íŒê²° ì¤‘...")
            prompt_final = f"ìµœì¢… íŒê²°: ì˜ìƒ ì œëª© '{title}', ë‰´ìŠ¤ ì¦ê±°: {news_ev}. ì§„ì‹¤ì´ë©´ 0-20, ê°€ì§œë©´ 80-100. JSON {{'score': int, 'reason': 'í•œê¸€íŒê²°ë¬¸'}}"
            res_f = call_mistral_judge(prompt_final)
            p_f = parse_ai_json(res_f)
            ai_score = safe_int_convert(p_f.get('score')) if p_f else 50
            
            final_prob = max(1, min(99, int((50 + t_impact + f_impact + news_penalty)*WEIGHT_ALGO + ai_score*WEIGHT_AI)))
            
            score_breakdown = [["ê¸°ë³¸ ì¤‘ë¦½ ì ìˆ˜", 50, "ë¶„ì„ ì‹œì‘ì "], ["ì§„ì‹¤ DB ë§¥ë½", t_impact, "ë‚´ë¶€ DB ë§¤ì¹­"], ["ê°€ì§œ íŒ¨í„´ ë§¥ë½", f_impact, "ë‚´ë¶€ DB ë§¤ì¹­"], ["ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_penalty, "í¬ë¡¤ë§ ê²°ê³¼"], ["AI ìµœì¢… íŒê²°", ai_score, p_f.get('reason','') if p_f else 'Error']]
            
            report = {
                "summary": full_text[:800], "news_evidence": news_ev, "ai_score": ai_score, "ai_reason": p_f.get('reason','') if p_f else 'Error',
                "score_breakdown": score_breakdown, "ts": ts, "fs": fs, "query": query, "tags": ", ".join(tags),
                "top_cmt_kw": top_cmt_kw, "cmt_rel": f"{rel_score}% ({rel_msg})", "red_cnt": red_cnt,
                "agitation": agitation, "cmt_count": len(cmts)
            }
            
            supabase.table("analysis_history").insert({"channel_name": uploader, "video_title": title, "fake_prob": final_prob, "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "video_url": url, "keywords": query, "detail_json": json.dumps(report, ensure_ascii=False)}).execute()
            my_bar.empty()
            render_report_full_ui(final_prob, db_count, title, uploader, report)

        except Exception as e: st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

def render_report_full_ui(prob, db_count, title, uploader, d, is_cached=False):
    if is_cached: st.success("ğŸ‰ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë°œê²¬ (Smart Cache)")

    st.subheader("ğŸ•µï¸ Dual-Engine Analysis Result")
    col_a, col_b, col_c = st.columns(3)
    col_a.metric("ìµœì¢… ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{prob}%")
    col_b.metric("AI íŒì •", "ğŸ”´ ìœ„í—˜" if prob > 60 else "ğŸŸ¢ ì•ˆì „" if prob < 30 else "ğŸŸ  ì£¼ì˜")
    col_c.metric("ì§€ëŠ¥ ë…¸ë“œ", f"{db_count} Nodes")
    
    st.divider()
    st.subheader("ğŸ§  Intelligence Map")
    render_intelligence_distribution(prob)

    st.divider()
    col1, col2 = st.columns([1, 1.4])
    with col1:
        st.write("**[ì˜ìƒ ìƒì„¸ ì •ë³´]**")
        st.table(pd.DataFrame({"í•­ëª©": ["ì˜ìƒ ì œëª©", "ì±„ë„ëª…", "í•´ì‹œíƒœê·¸"], "ë‚´ìš©": [title, uploader, d.get('tags','ì—†ìŒ')]}))
        st.info(f"ğŸ¯ Investigator ì¶”ì¶œ ê²€ìƒ‰ì–´: {d.get('query', 'N/A')}")
        with st.container(border=True):
            st.markdown("ğŸ“ **ì˜ìƒ ë‚´ìš© ìš”ì•½**")
            st.write(d.get('summary','ë‚´ìš© ì—†ìŒ'))
        render_score_breakdown(d.get('score_breakdown', []))

    with col2:
        st.subheader("ğŸ“Š 5ëŒ€ ì •ë°€ ë¶„ì„ ì¦ê±°")
        st.markdown("**[ì¦ê±° 0] Semantic Vector Space (Internal DB)**")
        colored_progress_bar("âœ… ì§„ì‹¤ ì˜ì—­ ê·¼ì ‘ë„", d.get('ts', 0), "#2ecc71")
        colored_progress_bar("ğŸš¨ ê±°ì§“ ì˜ì—­ ê·¼ì ‘ë„", d.get('fs', 0), "#e74c3c")
        
        st.markdown("**[ì¦ê±° 1] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡° (Deep-Web Crawler)**")
        if d.get('news_evidence'):
            st.dataframe(pd.DataFrame(d.get('news_evidence', [])), column_config={"ì›ë¬¸": st.column_config.LinkColumn("ë§í¬", display_text="ğŸ”— ì´ë™")}, hide_index=True)
        else: st.warning("ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("**[ì¦ê±° 2] ì‹œì²­ì ì—¬ë¡  ì‹¬ì¸µ ë¶„ì„**")
        st.table(pd.DataFrame([["ë¶„ì„ ëŒ“ê¸€ ìˆ˜", f"{d.get('cmt_count',0)}ê°œ"], ["ìµœë‹¤ ë¹ˆì¶œ í‚¤ì›Œë“œ", ", ".join(d.get('top_cmt_kw', []))], ["ë…¼ë€ ê°ì§€ ê±´ìˆ˜", f"{d.get('red_cnt',0)}ê±´"], ["ì£¼ì œ ì¼ì¹˜ë„", d.get('cmt_rel','0%')]], columns=["í•­ëª©", "ë‚´ìš©"]))
        
        st.markdown("**[ì¦ê±° 3] ìë§‰ ì„¸ë§Œí‹± ì‹¬ì¸µ ëŒ€ì¡°**")
        st.table(pd.DataFrame([["ì˜ìƒ ì£¼ìš” í‚¤ì›Œë“œ", "ë¶„ì„ ì™„ë£Œ"], ["ì„ ë™ì„± ì§€ìˆ˜", f"{d.get('agitation',0)}íšŒ"]], columns=["í•­ëª©", "ë‚´ìš©"]))
        
        st.markdown("**[ì¦ê±° 4] AI ìµœì¢… ë¶„ì„ íŒë‹¨ (Judge Verdict)**")
        with st.container(border=True): st.write(f"âš–ï¸ **íŒê²°:** {d.get('ai_reason', 'N/A')}")

# --- [7. UI ë ˆì´ì•„ì›ƒ ë° ê´€ë¦¬ì ê¸°ëŠ¥] ---

st.title("âš–ï¸ Fact-Check Center v99.6")

with st.container(border=True):
    st.markdown("### ğŸ›¡ï¸ ë²•ì  ê³ ì§€ ë° ì±…ì„ í•œê³„ (Disclaimer)\në³¸ ì„œë¹„ìŠ¤ëŠ” **ì¸ê³µì§€ëŠ¥(AI) ë° ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜**ìœ¼ë¡œ ì˜ìƒì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤. \në¶„ì„ ê²°ê³¼ëŠ” ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©°, ìµœì¢… íŒë‹¨ì˜ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("* **Engine A (Investigator)**: Gemini 1.5 Flash (í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§)\n* **Engine B (Judge)**: Mistral Large 2 (í•œê¸€ ì‹¬ì¸µ ë¶„ì„ ë° íŒê²°)")
    agree = st.checkbox("ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ì´ì— ë™ì˜í•©ë‹ˆë‹¤. (ë™ì˜ ì‹œ ë¶„ì„ ë²„íŠ¼ í™œì„±í™”)")

url_input = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL")
if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", disabled=not agree, use_container_width=True):
    if url_input: run_forensic_main(url_input)

st.divider()
st.subheader("ğŸ—‚ï¸ í•™ìŠµ ë°ì´í„° ê´€ë¦¬ (Cloud Knowledge Base)")
try:
    resp = supabase.table("analysis_history").select("*").order("id", desc=True).limit(20).execute()
    df_h = pd.DataFrame(resp.data)
    if not df_h.empty:
        if st.session_state["is_admin"]:
            df_h['Delete'] = False
            edited = st.data_editor(df_h[['Delete', 'id', 'analysis_date', 'video_title', 'fake_prob', 'keywords']], hide_index=True, use_container_width=True)
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ"):
                for _, row in edited[edited.Delete].iterrows():
                    supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                st.success("ì‚­ì œ ì™„ë£Œ")
                time.sleep(0.5)
                st.rerun()
        else: st.dataframe(df_h[['analysis_date', 'video_title', 'fake_prob', 'keywords']], use_container_width=True, hide_index=True)
except: pass

with st.expander("ğŸ” ê´€ë¦¬ì ì ‘ì† (Admin Access)"):
    if not st.session_state["is_admin"]:
        if st.text_input("Admin Password", type="password") == ADMIN_PASSWORD:
            st.session_state["is_admin"] = True
            st.rerun()
    else:
        st.success("ê´€ë¦¬ì ê¶Œí•œ í™œì„±í™”ë¨")
        if st.session_state["debug_logs"]:
            st.write("**ğŸ“œ ì‹¤ì‹œê°„ ë””ë²„ê·¸ ë¡œê·¸**")
            st.text_area("Logs", "\n".join(st.session_state["debug_logs"]), height=300)
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state["is_admin"] = False
            st.rerun()
