import streamlit as st
from supabase import create_client, Client
import re
import requests
import time
import random
import math
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from openai import OpenAI
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
import altair as alt
import json
from bs4 import BeautifulSoup

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° v99.8", layout="wide", page_icon="ğŸ›¡ï¸")

# ê¸€ë¡œë²Œ ìƒìˆ˜
STATIC_TRUTH_CORPUS = ["ë°•ë‚˜ë˜ ìœ„ì¥ì „ì… ë¬´í˜ì˜", "ì„ì˜ì›… ì•”í‘œ ëŒ€ì‘", "ì •í¬ì› ì €ì†ë…¸í™”", "ëŒ€ì „ ì¶©ë‚¨ í†µí•©", "ì„ ê±° ì¶œë§ˆ ì„ ì–¸"]
STATIC_FAKE_CORPUS = ["ì¶©ê²© í­ë¡œ ê²½ì•…", "ê¸´ê¸‰ ì†ë³´ ì†Œë¦„", "ì¶©ê²© ë°œì–¸ ë…¼ë€", "êµ¬ì† ì˜ì¥ ë°œë¶€", "ì˜ìƒ ìœ ì¶œ", "ê³„ì‹œ ì˜ˆì–¸", "ì‚¬í˜• ì§‘í–‰", "ìœ„ë…ì„¤"]
WEIGHT_ALGO = 0.6
WEIGHT_AI = 0.4
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']

if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False
if "debug_logs" not in st.session_state:
    st.session_state["debug_logs"] = []

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    GOOGLE_API_KEY_A = st.secrets["GOOGLE_API_KEY_A"]
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
except Exception as e:
    st.error(f"âŒ í•„ìˆ˜ í‚¤ ì„¤ì • ëˆ„ë½: {e}")
    st.stop()

mistral_client = OpenAI(api_key=MISTRAL_API_KEY, base_url="https://api.mistral.ai/v1")

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase = init_supabase()

# --- [2. ìœ í‹¸ë¦¬í‹° & íŒŒì„œ ê°•í™”] ---
def parse_ai_json(text):
    if not text: return None
    try:
        # ë§ˆí¬ë‹¤ìš´ ì œê±° ë¡œì§ ë³´ê°•
        clean_text = re.sub(r'```json\s*', '', text)
        clean_text = re.sub(r'```', '', clean_text).strip()
        parsed = json.loads(clean_text)
        if isinstance(parsed, list) and len(parsed) > 0: return parsed[0]
        return parsed
    except:
        try:
            # ì¤‘ê´„í˜¸ë§Œ ì¶”ì¶œ ì‹œë„
            match = re.search(r'(\{.*\})', text, re.DOTALL)
            if match: return json.loads(match.group(1))
        except: pass
    return None

def safe_get_score(data_dict, default=50):
    """Mistralì´ score ëŒ€ì‹  'ì ìˆ˜', 'fake_score' ë“±ìœ¼ë¡œ ë³´ë‚´ë„ ì°¾ì•„ë‚´ëŠ” í•¨ìˆ˜"""
    if not data_dict: return default
    for key in ['score', 'ì ìˆ˜', 'fake_score', 'rating', 'value']:
        if key in data_dict: return int(float(data_dict[key]))
    return default

def safe_get_reason(data_dict, default="ë¶„ì„ ê²°ê³¼ ì—†ìŒ"):
    if not data_dict: return default
    for key in ['reason', 'ì´ìœ ', 'ê·¼ê±°', 'íŒë‹¨', 'analysis']:
        if key in data_dict: return data_dict[key]
    return default

def extract_video_id(url):
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return match.group(1) if match else None

# --- [3. AI ëª¨ë¸ ì—”ì§„] ---
@st.cache_data(ttl=3600)
def get_all_available_gemini_models(api_key):
    genai.configure(api_key=api_key)
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        models.sort(key=lambda x: 0 if 'lite' in x else 1 if 'flash' in x else 2)
        return models
    except: return ["models/gemini-1.5-flash"]

def get_gemini_search_keywords_survivor(title, transcript):
    genai.configure(api_key=GOOGLE_API_KEY_A)
    models = get_all_available_gemini_models(GOOGLE_API_KEY_A)
    prompt = f"Role: Fact-Check Investigator. [Input] Title: {title}, Transcript: {transcript[:15000]}. [Task] Extract ONE Korean search query (2-4 words). Output ONLY the string."
    for m in models:
        try:
            model = genai.GenerativeModel(m)
            response = model.generate_content(prompt)
            if response.text:
                st.session_state["debug_logs"].append(f"âœ… Key A Success: {m}")
                return response.text.strip()
        except Exception as e:
            st.session_state["debug_logs"].append(f"âŒ Key A Failed ({m}): {str(e)[:50]}")
            continue
    return title

def call_mistral_judge(prompt):
    try:
        response = mistral_client.chat.completions.create(
            model="mistral-large-latest",
            messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íŒ©íŠ¸ì²´í¬ íŒì‚¬ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ê³  JSON í˜•ì‹({'score': int, 'reason': string})ë§Œ ì¤€ìˆ˜í•˜ì„¸ìš”."},
                      {"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.1
        )
        st.session_state["debug_logs"].append("âœ… Key B (Mistral) Verdict Success")
        return response.choices[0].message.content
    except Exception as e:
        st.session_state["debug_logs"].append(f"âŒ Key B Mistral Error: {e}")
        return None

# --- [4. ë¶„ì„ ì—”ì§„] ---
class VectorEngine:
    def __init__(self):
        self.vocab = set(); self.truth_vectors = []; self.fake_vectors = []
    def tokenize(self, text): return re.findall(r'[ê°€-í£]{2,}', text)
    def train(self, truth, fake):
        for t in truth + fake: self.vocab.update(self.tokenize(t))
        self.vocab = sorted(list(self.vocab))
        self.truth_vectors = [self.text_to_vector(t) for t in truth]
        self.fake_vectors = [self.text_to_vector(t) for t in fake]
    def text_to_vector(self, text):
        c = Counter(self.tokenize(text))
        return [c[w] for w in self.vocab]
    def cosine_similarity(self, v1, v2):
        dot = sum(a*b for a,b in zip(v1,v2))
        mag = math.sqrt(sum(a*a for a in v1)) * math.sqrt(sum(b*b for b in v2))
        return dot/mag if mag>0 else 0
    def analyze_position(self, query):
        if not self.vocab: return 0, 0
        qv = self.text_to_vector(query)
        mt = max([self.cosine_similarity(qv, v) for v in self.truth_vectors] or [0])
        mf = max([self.cosine_similarity(qv, v) for v in self.fake_vectors] or [0])
        return mt, mf

vector_engine = VectorEngine()

def fetch_comments_via_api(video_id):
    try:
        url = "https://www.googleapis.com/youtube/v3/commentThreads"
        res = requests.get(url, params={'part': 'snippet', 'videoId': video_id, 'key': YOUTUBE_API_KEY, 'maxResults': 50})
        items = [i['snippet']['topLevelComment']['snippet']['textDisplay'] for i in res.json().get('items', [])]
        return items, "Success"
    except: return [], "Fail"

# --- [5. UI ì»´í¬ë„ŒíŠ¸] ---
def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border: 1px solid #e0e0e0; border-radius: 8px; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; padding: 12px; text-align: left; } table.score-table td { padding: 12px; border-bottom: 1px solid #f0f0f0; } .badge-danger { background-color: #ffebee; color: #d32f2f; padding: 4px 8px; border-radius: 4px; font-weight: bold; } .badge-success { background-color: #e8f5e9; color: #2e7d32; padding: 4px 8px; border-radius: 4px; font-weight: bold; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            val = int(score)
            badge = f'<span class="badge-danger">+{val}</span>' if val > 0 else f'<span class="badge-success">{val}</span>' if val < 0 else "0"
        except: badge = str(score)
        rows += f"<tr><td>{item}<br><small style='color:#888;'>{note}</small></td><td style='text-align:right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª©</th><th style='text-align:right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def colored_progress_bar(label, percent, color):
    st.markdown(f"""<div style="margin-bottom: 10px;"><div style="display: flex; justify-content: space-between;"><span style="font-size: 13px; font-weight: 600;">{label}</span><span>{round(percent * 100, 1)}%</span></div><div style="background-color: #eee; height: 8px; border-radius: 5px;"><div style="background-color: {color}; height: 8px; width: {percent * 100}%; border-radius: 5px;"></div></div></div>""", unsafe_allow_html=True)

# --- [6. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜] ---
def run_forensic_main(url):
    st.session_state["debug_logs"] = []
    vid = extract_video_id(url)
    if not vid: return st.error("URL ì˜¤ë¥˜")

    # DB ë¡œë“œ & í•™ìŠµ
    res_t = supabase.table("analysis_history").select("video_title").lt("fake_prob", 40).execute()
    res_f = supabase.table("analysis_history").select("video_title").gt("fake_prob", 60).execute()
    dt, df = [r['video_title'] for r in res_t.data], [r['video_title'] for r in res_f.data]
    vector_engine.train(STATIC_TRUTH_CORPUS + dt, STATIC_FAKE_CORPUS + df)
    db_count = len(dt) + len(df)

    # ìºì‹œ ì²´í¬
    cached_res = supabase.table("analysis_history").select("*").ilike("video_url", f"%{vid}%").order("id", desc=True).limit(1).execute()
    if cached_res.data:
        c = cached_res.data[0]
        try:
            d = json.loads(c.get('detail_json', '{}'))
            render_report_full_ui(c['fake_prob'], db_count, c['video_title'], c['channel_name'], d, is_cached=True)
            return
        except: pass

    my_bar = st.progress(0, text="ë¶„ì„ ì‹œì‘...")
    with yt_dlp.YoutubeDL({'quiet': True, 'skip_download': True}) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            title, uploader, desc = info.get('title',''), info.get('uploader',''), info.get('description','')
            
            # ìë§‰/ëŒ“ê¸€ ìˆ˜ì§‘
            my_bar.progress(10, "1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            subs = info.get('subtitles') or {}; auto = info.get('automatic_captions') or {}; merged = {**subs, **auto}
            full_text = desc
            if 'ko' in merged:
                for f in merged['ko']:
                    if f['ext'] == 'vtt':
                        full_text = " ".join([l.strip() for l in requests.get(f['url']).text.splitlines() if l.strip() and '-->' not in l and '<' not in l])
                        break
            cmts, _ = fetch_comments_via_api(vid)

            # Key A
            my_bar.progress(30, "2ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            query = get_gemini_search_keywords_survivor(title, full_text)
            
            # Key B ë‰´ìŠ¤ ëŒ€ì¡°
            my_bar.progress(50, "3ë‹¨ê³„: ë‰´ìŠ¤ ëŒ€ì¡° ì¤‘...")
            rss = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR"
            items = re.findall(r'<item>(.*?)</item>', requests.get(rss).text, re.DOTALL)[:3]
            news_ev = []; max_match = 0
            for i in items:
                nt = re.search(r'<title>(.*?)</title>', i).group(1).replace("<![CDATA[", "").replace("]]>", "")
                nl = re.search(r'<link>(.*?)</link>', i).group(1)
                nd = re.search(r'<description>(.*?)</description>', i).group(1)
                
                res_b = call_mistral_judge(f"ì˜ìƒ[{title}] vs ë‰´ìŠ¤[{nt}]. ì¼ì¹˜ì—¬ë¶€ íŒë‹¨. JSON {{'score', 'reason'}}")
                p_b = parse_ai_json(res_b)
                s_b = safe_get_score(p_b, 50)
                if s_b > max_match: max_match = s_b
                news_ev.append({"ë‰´ìŠ¤ ì œëª©": nt, "ì¼ì¹˜ë„": f"{s_b}%", "ìµœì¢… ì ìˆ˜": s_b, "ë¶„ì„ ê·¼ê±°": safe_get_reason(p_b), "ì›ë¬¸": nl})

            # ì ìˆ˜ ê³„ì‚°
            ts, fs = vector_engine.analyze_position(query + " " + title)
            t_impact, f_impact = int(ts*30)*-1, int(fs*30)
            news_penalty = -30 if max_match <= 20 else (30 if max_match >= 80 else 0)
            
            # ìµœì¢… íŒê²°
            my_bar.progress(85, "4ë‹¨ê³„: AI ìµœì¢… íŒê²° ì¤‘...")
            res_f = call_mistral_judge(f"ì˜ìƒ '{title}', ë‰´ìŠ¤ ì¦ê±°: {news_ev}. ì§„ì‹¤ 0-20, ê°€ì§œ 80-100. JSON {{'score', 'reason'}}")
            p_f = parse_ai_json(res_f)
            ai_score = safe_get_score(p_f, 50)
            ai_reason = safe_get_reason(p_f)
            
            final_prob = max(1, min(99, int((50 + t_impact + f_impact + news_penalty)*WEIGHT_ALGO + ai_score*WEIGHT_AI)))
            
            score_breakdown = [["ê¸°ë³¸ ì ìˆ˜", 50, "ì¤‘ë¦½ ì‹œì‘"], ["ì§„ì‹¤ DB ë§¤ì¹­", t_impact, ""], ["ê°€ì§œ íŒ¨í„´ ë§¤ì¹­", f_impact, ""], ["ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_penalty, ""], ["AI íŒê²° ì ìˆ˜", ai_score, ai_reason]]
            
            report = {
                "summary": full_text[:800], "news_evidence": news_ev, "ai_score": ai_score, "ai_reason": ai_reason,
                "score_breakdown": score_breakdown, "ts": ts, "fs": fs, "query": query, "cmt_count": len(cmts)
            }
            
            supabase.table("analysis_history").insert({"channel_name": uploader, "video_title": title, "fake_prob": final_prob, "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "video_url": url, "keywords": query, "detail_json": json.dumps(report, ensure_ascii=False)}).execute()
            my_bar.empty()
            render_report_full_ui(final_prob, db_count, title, uploader, report)

        except Exception as e: st.error(f"ì˜¤ë¥˜: {e}")

def render_report_full_ui(prob, db_count, title, uploader, d, is_cached=False):
    if is_cached: st.success("ğŸ‰ ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ")
    st.subheader("ğŸ•µï¸ Dual-Engine Analysis Result")
    col_a, col_b, col_c = st.columns(3)
    col_a.metric("ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{prob}%")
    col_b.metric("AI íŒì •", "ğŸ”´ ìœ„í—˜" if prob > 60 else "ğŸŸ¢ ì•ˆì „" if prob < 30 else "ğŸŸ  ì£¼ì˜")
    col_c.metric("ì§€ëŠ¥ ë…¸ë“œ", f"{db_count} Nodes")
    
    col1, col2 = st.columns([1, 1.4])
    with col1:
        st.write(f"**ì œëª©:** {title}\n**ì±„ë„:** {uploader}")
        st.info(f"ğŸ¯ ê²€ìƒ‰ì–´: {d.get('query', 'N/A')}")
        render_score_breakdown(d.get('score_breakdown', []))
    with col2:
        st.write("ğŸ“Š **5ëŒ€ ì •ë°€ ë¶„ì„ ì¦ê±°**")
        colored_progress_bar("âœ… ì§„ì‹¤ ì˜ì—­ ê·¼ì ‘ë„", d.get('ts', 0), "#2ecc71")
        colored_progress_bar("ğŸš¨ ê±°ì§“ ì˜ì—­ ê·¼ì ‘ë„", d.get('fs', 0), "#e74c3c")
        st.markdown("**[ì¦ê±° 1] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡°**")
        st.dataframe(pd.DataFrame(d.get('news_evidence', [])), use_container_width=True, hide_index=True)
        with st.container(border=True): st.write(f"âš–ï¸ **AI íŒê²°:** {d.get('ai_reason', 'N/A')}")

# --- [7. UI ë ˆì´ì•„ì›ƒ] ---
st.title("âš–ï¸ Fact-Check Center v99.8")
with st.container(border=True):
    st.markdown("### ğŸ›¡ï¸ ë²•ì  ê³ ì§€")
    agree = st.checkbox("ë‚´ìš©ì„ í™•ì¸í–ˆìœ¼ë©° ë¶„ì„ì— ë™ì˜í•©ë‹ˆë‹¤.")

url_input = st.text_input("ğŸ”— URL")
if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", disabled=not agree): run_forensic_main(url_input)

st.divider()
try:
    resp = supabase.table("analysis_history").select("*").order("id", desc=True).limit(10).execute()
    df = pd.DataFrame(resp.data)
    if not df.empty:
        if st.session_state["is_admin"]:
            df['Delete'] = False
            edited = st.data_editor(df[['Delete', 'id', 'video_title', 'fake_prob', 'keywords']], hide_index=True, use_container_width=True)
            if st.button("ğŸ—‘ï¸ ì‚­ì œ"):
                for _, row in edited[edited.Delete].iterrows(): supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                st.rerun()
        else: st.dataframe(df[['analysis_date', 'video_title', 'fake_prob', 'keywords']], use_container_width=True, hide_index=True)
except: pass

with st.expander("ğŸ” ê´€ë¦¬ì ì „ìš©"):
    if not st.session_state["is_admin"]:
        if st.text_input("PW", type="password") == ADMIN_PASSWORD: st.session_state["is_admin"] = True; st.rerun()
    else:
        st.write(f"ğŸ¤– í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ (Gemini A + Mistral B) Active")
        if st.session_state["debug_logs"]: st.text_area("Debug Logs", "\n".join(st.session_state["debug_logs"]), height=300)
        if st.button("Logout"): st.session_state["is_admin"] = False; st.rerun()
