import streamlit as st
import sys
import traceback

# --- [ì´ˆì•ˆì „ ëª¨ë“œ ì„¤ì •] ---
st.set_page_config(page_title="Fact-Check v53.7 (Rescue)", layout="wide", page_icon="ğŸ›Ÿ")

# ì—ëŸ¬ ìº¡ì²˜ ë˜í¼ (ì•±ì´ ì£½ì§€ ì•Šê²Œ ë³´í˜¸)
def main_app():
    # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì—¬ê¸°ì„œ ì—ëŸ¬ë‚˜ë©´ ì¡í˜)
    from supabase import create_client, Client
    import re
    import requests
    import time
    import random
    import math
    from datetime import datetime
    from collections import Counter
    import yt_dlp
    import pandas as pd
    from bs4 import BeautifulSoup
    import altair as alt

    # ğŸŒŸ Secrets í™•ì¸
    try:
        YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
        SUPABASE_URL = st.secrets["SUPABASE_URL"]
        SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
        ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    except Exception as e:
        st.error(f"âŒ Secrets ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()

    @st.cache_resource
    def init_supabase():
        return create_client(SUPABASE_URL, SUPABASE_KEY)

    try:
        supabase = init_supabase()
    except Exception as e:
        st.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        st.stop()

    # --- [ìƒìˆ˜ ì •ì˜] ---
    WEIGHT_NEWS_DEFAULT = 45; WEIGHT_VECTOR = 35
    PENALTY_ABUSE = 20; PENALTY_NO_FACT = 25; PENALTY_SILENT_ECHO = 40
    
    VIP_ENTITIES = ['ìœ¤ì„ì—´', 'ëŒ€í†µë ¹', 'ì´ì¬ëª…', 'í•œë™í›ˆ', 'ê¹€ê±´í¬', 'ë¬¸ì¬ì¸', 'ë°•ê·¼í˜œ', 'ì´ëª…ë°•', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ', 'í‘¸í‹´', 'ì ¤ë ŒìŠ¤í‚¤', 'ì‹œì§„í•‘', 'ì •ì€', 'ì´ì¤€ì„', 'ì¡°êµ­', 'ì¶”ë¯¸ì• ', 'í™ì¤€í‘œ', 'ìœ ìŠ¹ë¯¼', 'ì•ˆì² ìˆ˜', 'ì†í¥ë¯¼', 'ì´ê°•ì¸', 'ê¹€ë¯¼ì¬', 'ë¥˜í˜„ì§„', 'ì¬ìš©', 'ì •ì˜ì„ ', 'ìµœíƒœì›', 'ë¥˜ì¤‘ì¼', 'ê°ë…', 'ì¡°ì„¸í˜¸', 'ìœ ì¬ì„', 'ì¥ë™ë¯¼', 'ìœ í˜¸ì •', 'ì´ì¬ë£¡', 'ì„ì„¸ë ¹']
    CRITICAL_STATE_KEYWORDS = ['ë³„ê±°', 'ì´í˜¼', 'íŒŒê²½', 'ì‚¬ë§', 'ìœ„ë…', 'êµ¬ì†', 'ì²´í¬', 'ì‹¤í˜•', 'ë¶ˆí™”', 'í­ë¡œ', 'ì¶©ê²©', 'ë…¼ë€', 'ì¤‘íƒœ', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'íŒŒì‚°', 'ë¹šë”ë¯¸', 'ì „ê³¼', 'ê°ì˜¥', 'ê°„ì²©']
    OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']

    # --- [í•µì‹¬ ë¡œì§: Pure Python NLP] ---
    def normalize_korean_word(word):
        # ì¡°ì‚¬ ì œê±° (Regex)
        josa_pattern = r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ë„|ë§Œ|í•œí…Œ|ì—ê²Œ|ì´ë‘|ê¹Œì§€|ë¶€í„°|ì¡°ì°¨|ë§ˆì €)$'
        if len(word) >= 2:
            return re.sub(josa_pattern, '', word)
        return word

    def extract_meaningful_tokens(text):
        raw_tokens = re.findall(r'[ê°€-í£]{2,}', text)
        noise = ['ì¶©ê²©', 'ê²½ì•…', 'ì†ë³´', 'ê¸´ê¸‰', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì§€ê¸ˆ', 'ê²°êµ­', 'ë‰´ìŠ¤', 'ì˜ìƒ', 'ëŒ€ë¶€ë¶„', 'ì´ìœ ', 'ì™œ', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•˜ëŠ”', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ì§„ì§œ', 'ì •ë§', 'ë„ˆë¬´', 'ê·¸ëƒ¥', 'ì´ì œ', 'ì‚¬ì‹¤', 'êµ­ë¯¼', 'ìš°ë¦¬', 'ëŒ€í•œë¯¼êµ­', 'ì—¬ëŸ¬ë¶„']
        return [normalize_korean_word(w) for w in raw_tokens if normalize_korean_word(w) not in noise]

    # ğŸŒŸ [v53.7] Logic-based Subject Detector
    def detect_subject_pure_logic(title, text):
        # 1. VIP ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­
        for vip in VIP_ENTITIES:
            if vip in title: return vip
        
        # 2. í˜¸ì¹­ ê¸°ë°˜ ì¶”ë¡ 
        honorifics = ['íšŒì¥', 'ì˜ì›', 'ëŒ€í‘œ', 'ëŒ€í†µë ¹', 'ì¥ê´€', 'ë°•ì‚¬', 'êµìˆ˜', 'ê°ë…', 'ì„ ìˆ˜', 'ì”¨', 'ë°°ìš°', 'ê°€ìˆ˜', 'ê°œê·¸ë§¨']
        words = title.split()
        for i, word in enumerate(words):
            for hon in honorifics:
                if hon in word and i > 0:
                    return normalize_korean_word(words[i-1])
        return ""

    def extract_action_pure_logic(title, transcript):
        t_tokens = set(extract_meaningful_tokens(title))
        tr_tokens = extract_meaningful_tokens(transcript[:1000])
        common = t_tokens.intersection(tr_tokens)
        common = [w for w in common if w not in VIP_ENTITIES]
        if common: return max(common, key=len)
        return ""

    def generate_smart_query(title, transcript):
        subject = detect_subject_pure_logic(title, transcript)
        action = extract_action_pure_logic(title, transcript)
        
        if not subject:
            tokens = extract_meaningful_tokens(title)
            subject = tokens[0] if tokens else ""
            
        final_query = f"{subject} {action}".strip()
        if len(final_query) < 3:
            final_query = " ".join(extract_meaningful_tokens(title)[:3])
        return final_query

    # --- [Data Functions] ---
    def save_analysis(channel, title, prob, url, keywords):
        try: supabase.table("analysis_history").insert({"channel_name": channel, "video_title": title, "fake_prob": prob, "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "video_url": url, "keywords": keywords}).execute()
        except: pass

    def get_db_stats():
        try:
            res = supabase.table("analysis_history").select("fake_prob").execute()
            if res.data:
                df = pd.DataFrame(res.data)
                return len(df), len(df[df['fake_prob'] < 40]), len(df[df['fake_prob'] > 60]), df
        except: pass
        return 0, 0, 0, pd.DataFrame()

    # --- [Utils] ---
    def summarize_transcript(text, title):
        if not text or len(text) < 50: return "âš ï¸ ë‚´ìš© ë¶€ì¡±"
        clean = re.sub(r'http\S+|#EXTM3U|#EXT-X-VERSION:3|\[.*?\]|[>]+', '', text)
        sentences = re.split(r'(?<=[.?!])\s+', clean)
        if len(sentences) <= 3: return clean.strip()
        
        # ê°„ë‹¨ ìš”ì•½ ë¡œì§
        title_tokens = set(extract_meaningful_tokens(title))
        scored = []
        for i, s in enumerate(sentences):
            if len(s) < 15: continue
            score = sum(1 for w in extract_meaningful_tokens(s) if w in title_tokens) * 5
            if i < len(sentences)*0.2: score += 2
            scored.append((i, s, score))
        
        top = sorted(scored, key=lambda x:x[2], reverse=True)[:3]
        top.sort(key=lambda x:x[0])
        return " ".join([s[1] for s in top])

    def fetch_real_transcript(info):
        try:
            url = None
            for key in ['subtitles', 'automatic_captions']:
                if key in info and 'ko' in info[key]:
                    for fmt in info[key]['ko']:
                        if fmt['ext'] == 'vtt': url = fmt['url']; break
                if url: break
            if url:
                res = requests.get(url)
                if res.status_code == 200 and "#EXTM3U" not in res.text:
                    clean = []
                    for line in res.text.splitlines():
                        if '-->' not in line and 'WEBVTT' not in line and line.strip():
                            t = re.sub(r'<[^>]+>', '', line).strip()
                            if t and t not in clean: clean.append(t)
                    return " ".join(clean)
        except: pass
        return info.get('description', '')

    def fetch_news_regex(query):
        news_res = []
        try:
            rss = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR"
            raw = requests.get(rss, timeout=5).text
            items = re.findall(r'<item>(.*?)</item>', raw, re.DOTALL)
            for item in items[:10]:
                t = re.search(r'<title>(.*?)</title>', item)
                nt = t.group(1).replace("<![CDATA[", "").replace("]]>", "") if t else ""
                news_res.append({'title': nt})
        except: pass
        return news_res

    def calculate_match(news_item, query_str, transcript):
        # 1. ë‰´ìŠ¤ ì œëª©ê³¼ ì¿¼ë¦¬ ì¼ì¹˜ë„
        t_tokens = set(extract_meaningful_tokens(news_item['title']))
        q_tokens = set(extract_meaningful_tokens(query_str))
        score = 100 if len(q_tokens & t_tokens) >= 2 else 50 if len(q_tokens & t_tokens) >= 1 else 0
        
        # 2. Critical Check
        for crit in CRITICAL_STATE_KEYWORDS:
            if crit in query_str and crit not in news_item['title']:
                return 0
        return score

    # --- [UI] ---
    with st.sidebar:
        st.header("ğŸ›¡ï¸ ê´€ë¦¬ì ë©”ë‰´")
        if st.session_state.get("is_admin", False):
            st.success("âœ… ë¡œê·¸ì¸ë¨")
            if st.button("ë¡œê·¸ì•„ì›ƒ"): st.session_state["is_admin"] = False; st.rerun()
        else:
            with st.form("login"):
                if st.form_submit_button("ë¡œê·¸ì¸"):
                    if st.text_input("PW", type="password") == ADMIN_PASSWORD:
                        st.session_state["is_admin"] = True; st.rerun()

    st.title("âš–ï¸ Fact-Check Center v53.7 (Rescue)")
    
    total, t_cnt, f_cnt, df_stats = get_db_stats()
    
    url = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL")
    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘") and url:
        with st.status("ğŸ•µï¸ ë¶„ì„ ì¤‘...", expanded=True) as status:
            st.write("ğŸ“¡ ì˜ìƒ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
                info = ydl.extract_info(url, download=False)
                title = info.get('title', '')
                uploader = info.get('uploader', '')
                tags = info.get('tags', [])
                full_text = fetch_real_transcript(info)
            
            st.write("ğŸ§  ìŠ¤ë§ˆíŠ¸ ì¿¼ë¦¬ ìƒì„± ì¤‘...")
            query = generate_smart_query(title, full_text)
            
            st.write(f"ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘: {query}")
            news_items = fetch_news_regex(query)
            
            max_match = 0
            verified_news = []
            for item in news_items:
                m = calculate_match(item, query, full_text)
                if m > max_match: max_match = m
                verified_news.append({'ë‰´ìŠ¤ ì œëª©': item['title'], 'ì¼ì¹˜ë„': f"{m}%"})
            
            # ì ìˆ˜ ì‚°ì •
            is_silent = (len(news_items) == 0) or (max_match < 20)
            has_critical = any(k in title for k in CRITICAL_STATE_KEYWORDS)
            agitation = sum(title.count(w) + full_text.count(w) for w in ['ì¶©ê²©','ê²½ì•…','í­ë¡œ','ì†ë³´'])
            
            score = 50 # Base
            
            note = ""
            if is_silent:
                if has_critical:
                    score += 5; note = "âš ï¸ ë¯¸ê²€ì¦ ìœ„í—˜ ì£¼ì¥ (+5)"
                elif agitation >= 3:
                    score += 40; note = "ğŸ”‡ ì¹¨ë¬µì˜ ë©”ì•„ë¦¬ (+40)"
            else:
                if max_match >= 60: score -= 45; note = "âœ… ë‰´ìŠ¤ ê²€ì¦ ì™„ë£Œ (-45)"
                else: score += 15; note = "âš ï¸ ë‚®ì€ ì¼ì¹˜ë„ (+15)"
            
            if any(o in uploader.upper() for o in OFFICIAL_CHANNELS):
                score = 5; note = "ğŸ›¡ï¸ ê³µì‹ ì–¸ë¡ ì‚¬"

            save_analysis(uploader, title, score, url, query)
            status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete")

        # ê²°ê³¼ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{score}%", delta=note)
            st.info(f"ğŸ¯ ê²€ìƒ‰ì–´: {query}")
            st.caption(summarize_transcript(full_text, title))
            
        with col2:
            st.subheader("ë‰´ìŠ¤ ëŒ€ì¡° ê²°ê³¼")
            if verified_news: st.table(pd.DataFrame(verified_news))
            else: st.warning("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            if not df_stats.empty:
                st.subheader("DB ë¶„í¬ë„")
                c = alt.Chart(df_stats).transform_density('fake_prob', as_=['fake_prob', 'density'], extent=[0, 100]).mark_area(opacity=0.3).encode(x='fake_prob:Q', y='density:Q')
                rule = alt.Chart(pd.DataFrame({'x': [score]})).mark_rule(color='red').encode(x='x')
                st.altair_chart(c + rule, use_container_width=True)

# ì‹¤í–‰ ì§„ì…ì  (Crash Catch)
if __name__ == "__main__":
    try:
        main_app()
    except Exception as e:
        st.error("ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ (ì•± ë³´í˜¸ ëª¨ë“œ)")
        st.code(traceback.format_exc())
        st.info("ê´€ë¦¬ìì—ê²Œ ìœ„ ì—ëŸ¬ ì½”ë“œë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.")
