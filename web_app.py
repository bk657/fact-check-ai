import streamlit as st
from supabase import create_client, Client
import re
import requests
import time
import random
import math
import os
import json
from collections import Counter
from datetime import datetime

# --- [ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸] ---
from mistralai import Mistral
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import yt_dlp
import pandas as pd
import altair as alt
from bs4 import BeautifulSoup

# --- [1. ì‹œìŠ¤í…œ ì„¤ì • ë° CSS ìµœì í™”] ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° (Triple Engine)", layout="wide", page_icon="ğŸ›¡ï¸")

# [Mobile/Web UI ìµœì í™” CSS]
st.markdown("""
    <style>
        .block-container { padding-top: 3.5rem !important; padding-bottom: 5rem; }
        .stMetric { background-color: #f8f9fa; padding: 10px; border-radius: 8px; border: 1px solid #eee; text-align: center; }
        div[data-testid="stMetricValue"] { font-size: 1.3rem !important; }
        h1 { font-size: 1.8rem !important; padding-bottom: 10px; }
        h3 { font-size: 1.2rem !important; margin-top: 20px !important; }
        .risk-badge { padding: 5px 10px; border-radius: 5px; font-weight: bold; color: white; }
    </style>
""", unsafe_allow_html=True)

if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False
if "debug_logs" not in st.session_state:
    st.session_state["debug_logs"] = []

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
    GOOGLE_API_KEY_A = st.secrets["GOOGLE_API_KEY_A"]
    GOOGLE_API_KEY_B = st.secrets["GOOGLE_API_KEY_B"]
except:
    st.error("âŒ secrets.toml íŒŒì¼ì— API Key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_clients():
    su = create_client(SUPABASE_URL, SUPABASE_KEY)
    mi = Mistral(api_key=MISTRAL_API_KEY)
    return su, mi

supabase, mistral_client = init_clients()

# --- [2. ëª¨ë¸ ì •ì˜] ---
MISTRAL_MODELS = ["mistral-large-latest", "mistral-medium-latest", "mistral-small-latest"]

def get_gemini_models_dynamic(api_key):
    genai.configure(api_key=api_key)
    try:
        models = [m.name.replace("models/", "") for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        models.sort(key=lambda x: 0 if 'flash' in x else 1 if 'pro' in x else 2)
        return models
    except: return ["gemini-2.0-flash", "gemini-1.5-flash"]

# --- [3. ìœ í‹¸ë¦¬í‹°] ---
def parse_llm_json(text):
    try:
        parsed = json.loads(text)
    except:
        try:
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```', '', text)
            match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
            if match: parsed = json.loads(match.group(1))
            else: return None
        except: return None
    if isinstance(parsed, list): return parsed[0] if len(parsed) > 0 and isinstance(parsed[0], dict) else None
    if isinstance(parsed, dict): return parsed
    return None

def determine_risk_level(prob):
    if prob >= 70: return "â›” ìœ„í—˜ (High Risk)", "#d32f2f" # Red
    elif prob >= 40: return "âš ï¸ ì£¼ì˜ (Caution)", "#f57c00" # Orange
    return "âœ… ì•ˆì „ (Safe)", "#388e3c" # Green

def colored_bar_html(label, score, color):
    pct = min(100, max(0, int(score * 100)))
    return f"""
    <div style="margin-bottom: 6px;">
        <div style="display: flex; justify-content: space-between; font-size: 13px; font-weight: 600; color: #444;">
            <span>{label}</span>
            <span>{pct}%</span>
        </div>
        <div style="width: 100%; background-color: #e0e0e0; border-radius: 6px; height: 8px; margin-top: 2px;">
            <div style="width: {pct}%; background-color: {color}; height: 8px; border-radius: 6px;"></div>
        </div>
    </div>
    """

# --- [4. Core Logic] ---
def call_triple_survivor(prompt, is_json=False):
    logs = []
    response_format = {"type": "json_object"} if is_json else None
    
    # Mistral
    for model_name in MISTRAL_MODELS:
        try:
            resp = mistral_client.chat.complete(
                model=model_name, messages=[{"role": "user", "content": prompt}],
                response_format=response_format, temperature=0.2
            )
            if resp.choices:
                logs.append(f"âœ… Success (Mistral): {model_name}")
                return resp.choices[0].message.content, model_name, logs
        except Exception as e:
            logs.append(f"âŒ Mistral Failed: {str(e)[:20]}")
            continue

    # Gemini A & B
    generation_config = {"response_mime_type": "application/json"} if is_json else {}
    for key_name, key_val in [("Key A", GOOGLE_API_KEY_A), ("Key B", GOOGLE_API_KEY_B)]:
        logs.append(f"âš ï¸ Mistral Failed -> Gemini {key_name} íˆ¬ì…")
        genai.configure(api_key=key_val)
        models = get_gemini_models_dynamic(key_val)
        for model_name in models:
            try:
                model = genai.GenerativeModel(model_name, generation_config=generation_config)
                resp = model.generate_content(prompt)
                if resp.text:
                    logs.append(f"âœ… Success (Gemini {key_name}): {model_name}")
                    return resp.text, f"{model_name} ({key_name})", logs
            except: continue
            
    return None, "All Failed", logs

# --- [5. Data & Engine] ---
WEIGHT_ALGO = 0.85
WEIGHT_AI = 0.15
OFFICIAL_CHANNELS = ['MBC','KBS','SBS','EBS','YTN','JTBC','TVCHOSUN','MBN','CHANNEL A','ì—°í•©ë‰´ìŠ¤','YONHAP','í•œê²¨ë ˆ','ê²½í–¥','ì¡°ì„ ','ì¤‘ì•™','ë™ì•„']
CRITICAL_STATE_KEYWORDS = ['ë³„ê±°','ì´í˜¼','íŒŒê²½','ì‚¬ë§','ìœ„ë…','êµ¬ì†','ì²´í¬','ì‹¤í˜•','ë¶ˆí™”','í­ë¡œ','ì¶©ê²©','ë…¼ë€','ì‹¬ì •ì§€','ë‡Œì‚¬','ì••ìˆ˜ìˆ˜ìƒ‰','ê°ì˜¥']
STATIC_TRUTH = ["ë°•ë‚˜ë˜ ìœ„ì¥ì „ì… ë¬´í˜ì˜", "ì„ì˜ì›… ì•”í‘œ ëŒ€ì‘", "ì •í¬ì› ì €ì†ë…¸í™”", "ì„ ê±° ì¶œë§ˆ ì„ ì–¸"]
STATIC_FAKE = ["ì¶©ê²© í­ë¡œ ê²½ì•…", "ê¸´ê¸‰ ì†ë³´ ì†Œë¦„", "êµ¬ì† ì˜ì¥ ë°œë¶€", "ì‚¬í˜• ì§‘í–‰", "ìœ„ë…ì„¤"]

class VectorEngine:
    def __init__(self): self.vocab=set(); self.truth=[]; self.fake=[]
    def tokenize(self, t): return re.findall(r'[ê°€-í£]{2,}', t)
    def train(self, t_list, f_list):
        for t in t_list+f_list: self.vocab.update(self.tokenize(t))
        self.vocab = sorted(list(self.vocab))
        self.truth = [self.vec(t) for t in t_list]
        self.fake = [self.vec(t) for t in f_list]
    def vec(self, t):
        c = Counter(self.tokenize(t))
        return [c[w] for w in self.vocab]
    def sim(self, v1, v2):
        dot = sum(a*b for a,b in zip(v1,v2))
        mag = math.sqrt(sum(a*a for a in v1))*math.sqrt(sum(b*b for b in v2))
        return dot/mag if mag>0 else 0
    def analyze(self, q):
        qv = self.vec(q)
        return max([self.sim(qv,v) for v in self.truth] or [0]), max([self.sim(qv,v) for v in self.fake] or [0])

vector_engine = VectorEngine()

# [ìˆ˜ì •] 3-Way ì „ëµ ëª…ì‹œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
def get_keywords(title, trans):
    prompt = f"""
    You are a Fact-Check Investigator.
    [Input] Title: {title}, Transcript: {trans[:10000]}
    [Task] Generate 3 diverse Google News search queries to verify this video.
    1. Specific: Entity + Exact Event (Specific Incident)
    2. Broader: Main Subject + Status (Contextual)
    3. Keywords: Core Nouns Combination
    
    [Output JSON] {{ "queries": ["query1", "query2", "query3"] }}
    """
    res, model, logs = call_triple_survivor(prompt, is_json=True)
    st.session_state["debug_logs"].extend([f"[Key] {l}" for l in logs])
    parsed = parse_llm_json(res)
    # íŒŒì‹± ì„±ê³µ ì‹œ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, ì‹¤íŒ¨ ì‹œ ì œëª© ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if parsed and 'queries' in parsed and isinstance(parsed['queries'], list):
        return parsed['queries'], model
    return [title, title + " ë‰´ìŠ¤", title + " íŒ©íŠ¸ì²´í¬"], model

def scrape_news(url):
    try:
        res = requests.get(url, timeout=5, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        for t in soup(['script','style','nav','footer']): t.decompose()
        text = " ".join([p.get_text().strip() for p in soup.find_all('p') if len(p.get_text())>30])
        return (text[:3000], res.url) if len(text)>100 else (None, res.url)
    except: return None, url

def verify_news(summary, link, snippet):
    txt, real_url = scrape_news(link)
    ev = txt if txt else snippet
    prompt = f"Compare Video({summary[:1000]}) vs News({ev}). Match(90-100)/Related(40-60)/Mismatch(0-10). Output JSON: {{ \"score\": int, \"reason\": \"korean short\" }}"
    res, _, logs = call_triple_survivor(prompt, is_json=True)
    st.session_state["debug_logs"].extend([f"[Verify] {l}" for l in logs])
    p = parse_llm_json(res)
    return (p['score'], p['reason'], "Full" if txt else "Snippet", real_url) if p else (0, "Err", "Err", link)

def judge_final(title, trans, evidences):
    ev_text = "".join([f"- {e['ë‰´ìŠ¤ ì œëª©']} (Score:{e['ìµœì¢… ì ìˆ˜']}, Reason:{e['ë¶„ì„ ê·¼ê±°']})\n" for e in evidences])
    prompt = f"Judge Video: {title}. Evidence: {ev_text}. Decide Fake Probability (0-100). Output JSON: {{ \"score\": int, \"reason\": \"korean explanation\" }}"
    res, model, logs = call_triple_survivor(prompt, is_json=True)
    st.session_state["debug_logs"].extend([f"[Judge] {l}" for l in logs])
    p = parse_llm_json(res)
    return (p['score'], f"{p['reason']} ({model})") if p else (50, "Failed")

def generate_comprehensive_summary(title, final_prob, news_ev, red_cnt, ai_reason, risk_text):
    prompt = f"""
    ë‹¹ì‹ ì€ íŒ©íŠ¸ì²´í¬ ì „ë¬¸ AI ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ë¶„ì„ ë°ì´í„°]
    - ì˜ìƒ ì œëª©: {title}
    - ìµœì¢… ê°€ì§œë‰´ìŠ¤ í™•ë¥ : {final_prob}% ({risk_text})
    - ë‰´ìŠ¤ ëŒ€ì¡° ê²°ê³¼: {len(news_ev)}ê°œì˜ ê¸°ì‚¬ì™€ ëŒ€ì¡°ë¨
    - ì„ ë™ì„± ëŒ“ê¸€ ê°ì§€: {red_cnt}ê°œ
    - AI íŒë‹¨ ìš”ì•½: {ai_reason}
    
    [ìš”ì²­ì‚¬í•­]
    1. ì´ ì˜ìƒì´ ì™œ {final_prob}% ì ìˆ˜ë¥¼ ë°›ì•˜ëŠ”ì§€ í•µì‹¬ ì´ìœ ë¥¼ ìš”ì•½í•˜ì„¸ìš”.
    2. ë‰´ìŠ¤ ì¦ê±°ì™€ì˜ ì¼ì¹˜ ì—¬ë¶€, ì œëª©ì˜ ì–´ê·¸ë¡œì„±, ì—¬ë¡  ë°˜ì‘ì„ ì¢…í•©ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.
    3. ì‚¬ìš©ìì—ê²Œ "ë¯¿ì–´ë„ ë˜ëŠ”ì§€", "ì£¼ì˜í•´ì•¼ í•˜ëŠ”ì§€" ëª…í™•í•œ í–‰ë™ ê°€ì´ë“œë¥¼ ì œì‹œí•˜ì„¸ìš”.
    4. í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ìµœëŒ€ 4ë¬¸ì¥)
    """
    res, _, _ = call_triple_survivor(prompt, is_json=False)
    return res if res else "ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# --- [6. Helper Functions] ---
def normalize(w): return re.sub(r'ì€$|ëŠ”$|ì´$|ê°€$|ì„$|ë¥¼$|ì˜$|ì—$|ë¡œ$', '', re.sub(r'[^ê°€-í£0-9]', '', w))
def get_tokens(t): return [normalize(w) for w in re.findall(r'[ê°€-í£]{2,}', t) if w not in ['ì¶©ê²©','ì†ë³´','ë‰´ìŠ¤']]
def get_top_kw(t): return Counter(get_tokens(t)).most_common(5)
def check_official(n): return any(o in n.upper().replace(" ","") for o in OFFICIAL_CHANNELS)
def count_agitation(t): return sum(t.count(w) for w in ['ì¶©ê²©','ê²½ì•…','ì‹¤ì²´','í­ë¡œ','ì†ë³´','ì†Œë¦„'])
def check_red_flags(cmts): 
    d = [k for c in cmts for k in ['ê°€ì§œ','ì£¼ì‘','êµ¬ë¼','í—ˆìœ„','ì„ ë™'] if k in c]
    return len(d), list(set(d))

# --- [Data Fetching] ---
def fetch_transcript(info):
    try:
        url = None
        for fmt in (info.get('subtitles') or {}).get('ko', []) + (info.get('automatic_captions') or {}).get('ko', []):
            if fmt['ext'] == 'vtt': url = fmt['url']; break
        if url: return " ".join([l.strip() for l in requests.get(url).text.splitlines() if l.strip() and '-->' not in l and '<' not in l]), "Success"
    except: pass
    return None, "Fail"

def fetch_comments(vid):
    try:
        res = requests.get("https://www.googleapis.com/youtube/v3/commentThreads", params={'part':'snippet','videoId':vid,'key':YOUTUBE_API_KEY,'maxResults':50})
        if res.status_code==200: return [str(i['snippet']['topLevelComment']['snippet']['textDisplay']) for i in res.json().get('items',[])]
    except: pass
    return []

def fetch_news(q):
    try:
        raw = requests.get(f"https://news.google.com/rss/search?q={requests.utils.quote(q)}&hl=ko&gl=KR", timeout=5).text
        items = re.findall(r'<item>(.*?)</item>', raw, re.DOTALL)
        res = []
        for i in items[:10]:
            t = re.search(r'<title>(.*?)</title>', i); l = re.search(r'<link>(.*?)</link>', i)
            if t and l: res.append({'title':t.group(1).replace("<![CDATA[","").replace("]]>",""), 'link':l.group(1).strip()})
        return res
    except: return []

def analyze_comments(cmts, ctx):
    if not cmts: return [], 0, "ë°ì´í„° ë¶€ì¡±"
    safe_cmts = " ".join([str(c) for c in cmts])
    top = Counter(get_tokens(safe_cmts)).most_common(5)
    ctx_set = set(get_tokens(ctx))
    score = int(sum(1 for w,c in top if w in ctx_set)/len(top)*100) if top else 0
    return [f"{w}({c})" for w,c in top], score, "ë†’ìŒ" if score>=60 else "ë³´í†µ" if score>=20 else "ë‚®ìŒ"

def save_db(ch, ti, pr, url, kw, detail):
    try: supabase.table("analysis_history").insert({
        "channel_name":ch, "video_title":ti, "fake_prob":pr, "video_url":url, 
        "keywords":kw, "detail_json":json.dumps(detail, ensure_ascii=False),
        "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }).execute()
    except Exception as e: print(f"DB Error: {e}")

# --- [UI ë Œë”ë§ í•¨ìˆ˜ (Conclusion First)] ---
def render_report_full_ui(prob, db_count, title, channel, data, is_cached=False):
    st.divider()
    if is_cached: st.info(f"ğŸ’¾ ê³¼ê±° ë¶„ì„ ê¸°ë¡ í˜¸ì¶œë¨ (ì´ DB ë°ì´í„°: {db_count}ê°œ)")
    
    risk_text, risk_color = determine_risk_level(prob)
    
    # 1. [HERO SECTION] Score & Risk (ìµœìƒë‹¨)
    c1, c2, c3 = st.columns([2, 2, 1])
    with c1: st.metric("ğŸ”¥ ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{prob}%")
    with c2: st.markdown(f"<div style='text-align:center; padding:10px; border-radius:10px; background-color:{risk_color}; color:white; font-weight:bold; font-size:1.1rem; margin-top:5px;'>{risk_text}</div>", unsafe_allow_html=True)
    with c3: st.metric("ğŸ—„ï¸ ëˆ„ì  DB", f"{db_count}ê±´")
    
    # 2. [FINAL SUMMARY] AI ì¢…í•© ë¦¬í¬íŠ¸ (ë°”ë¡œ ì•„ë˜ ë°°ì¹˜)
    st.subheader("ğŸ“ AI ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸")
    with st.container(border=True):
        st.markdown(f"**ğŸ“¢ AI Analyst Comment:**\n\n{data.get('final_summary', 'ë¶„ì„ ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')}")

    # 3. [VIDEO INFO] ì˜ìƒ ê¸°ë³¸ ì •ë³´
    st.subheader("â„¹ï¸ ì˜ìƒ ê¸°ë³¸ ì •ë³´")
    with st.container(border=True):
        st.write(f"**ğŸ“º {title}**")
        st.caption(f"ì±„ë„: {channel} | ë¶„ì„ì¼: {datetime.now().strftime('%Y-%m-%d')}")
        st.info(f"**ë‚´ìš© ìš”ì•½:** {data.get('summary', 'ìš”ì•½ ì—†ìŒ')}")
        with st.expander("ìƒì„¸ ë©”íƒ€ë°ì´í„° ë³´ê¸°"):
            st.dataframe(pd.DataFrame([data.get('meta', {})]), use_container_width=True, hide_index=True)

    # 4. [EVIDENCE TABS] ìƒì„¸ ì¦ê±° ìë£Œ (íƒ­ìœ¼ë¡œ ë¶„ë¦¬)
    st.subheader("ğŸ” ìƒì„¸ ì¦ê±° ë° ë¶„ì„ ë°ì´í„°")
    tab_news, tab_data, tab_ai = st.tabs(["ğŸ“° ë‰´ìŠ¤ íŒ©íŠ¸ì²´í¬", "ğŸ“Š ë°ì´í„°/ì—¬ë¡ ", "ğŸ¤– AI ê¸°ìˆ ì  íŒë‹¨"])
    
    # [Tab 1: News Check]
    with tab_news:
        # [NEW] ê²€ìƒ‰ í‚¤ì›Œë“œ ì •ë³´ í‘œì‹œ (3-Way)
        st.markdown("###### ğŸ—ï¸ AI ê²€ìƒ‰ í‚¤ì›Œë“œ (3-Way Strategy)")
        if data.get('query_list'):
            # ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
            q_list_formatted = " | ".join([f"`{q}`" for q in data['query_list']])
            st.caption(f"AIê°€ ì¶”ì¶œí•œ 3ê°€ì§€ ì „ëµ í‚¤ì›Œë“œ:\n{q_list_formatted}")
        
        if data.get('query'):
            st.success(f"âœ… ë‰´ìŠ¤ ê²€ìƒ‰ì— ì„±ê³µí•œ ìµœì¢… í‚¤ì›Œë“œ: **{data['query']}**")
        
        st.divider()
        st.write("###### [ì¦ê±° 2] ì£¼ìš” ë‰´ìŠ¤ ëŒ€ì¡° ê²°ê³¼ (Top 5)")
        if data.get('news_evidence'):
            for news in data['news_evidence']:
                with st.expander(f"{news['ì¼ì¹˜ë„']} {news['ë‰´ìŠ¤ ì œëª©']}"):
                    st.write(f"**ğŸ•µï¸ ë¶„ì„ ê·¼ê±°:** {news['ë¶„ì„ ê·¼ê±°']}")
                    st.caption(f"ì¶œì²˜: {news['ë¹„ê³ ']}")
                    st.link_button("ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°", news['ì›ë¬¸'])
        else:
            st.warning("ê´€ë ¨ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # [Tab 2: Data & Sentiment]
    with tab_data:
        st.write("###### [ì¦ê±° 1] ë°ì´í„° ìœ ì‚¬ë„ ë¶„ì„")
        c1, c2 = st.columns(2)
        with c1: st.markdown(colored_bar_html("ì§„ì‹¤ ë°ì´í„° ìœ ì‚¬ë„", data.get('ts', 0), "#4CAF50"), unsafe_allow_html=True)
        with c2: st.markdown(colored_bar_html("ê°€ì§œ ë°ì´í„° ìœ ì‚¬ë„", data.get('fs', 0), "#F44336"), unsafe_allow_html=True)
        
        st.caption("â€» ì „ì²´ DB ë¶„í¬ ë‚´ í˜„ì¬ ì˜ìƒ ìœ„ì¹˜")
        render_intelligence_distribution(prob)
        
        st.divider()
        st.write("###### [ì¦ê±° 3] ëŒ“ê¸€ ì—¬ë¡  ë¶„ì„")
        col_c1, col_c2, col_c3 = st.columns(3)
        with col_c1: st.metric("ëŒ“ê¸€ ìˆ˜", f"{data.get('cmt_count', 0)}")
        with col_c2: st.metric("ì£¼ì œ ì—°ê´€ì„±", data.get('cmt_rel', '-'))
        with col_c3: st.metric("ì„ ë™ ì˜ì‹¬ ëŒ“ê¸€", f"{data.get('red_cnt', 0)}")
        
        if data.get('top_cmt_kw'):
            st.write(f"ğŸ—£ï¸ **ì£¼ìš” í‚¤ì›Œë“œ:** {', '.join(data['top_cmt_kw'])}")

    # [Tab 3: AI Logic]
    with tab_ai:
        st.write("###### [ì¦ê±° 4] AI ê¸°ìˆ ì  íŒë‹¨ ë¡œì§")
        st.info(f"**ğŸ¤– Internal Logic:**\n{data.get('ai_reason', 'íŒë‹¨ ë³´ë¥˜')}")
        
        st.write("###### ğŸ”¢ ì ìˆ˜ ì‚°ì • ë‚´ì—­ (Score Breakdown)")
        if data.get('score_breakdown'):
            render_score_breakdown(data['score_breakdown'])


def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border-spacing: 0; border: 1px solid #e0e0e0; border-radius: 8px; overflow: hidden; font-family: sans-serif; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; color: #495057; font-weight: bold; padding: 12px 15px; text-align: left; border-bottom: 1px solid #e0e0e0; } table.score-table td { padding: 12px 15px; border-bottom: 1px solid #f0f0f0; color: #333; } table.score-table tr:last-child td { border-bottom: none; } .badge { padding: 4px 8px; border-radius: 6px; font-weight: 700; font-size: 11px; display: inline-block; text-align: center; min-width: 45px; } .badge-danger { background-color: #ffebee; color: #d32f2f; } .badge-success { background-color: #e8f5e9; color: #2e7d32; } .badge-neutral { background-color: #f5f5f5; color: #757575; border: 1px solid #e0e0e0; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            score_num = int(score)
            badge = f'<span class="badge badge-danger">+{score_num}</span>' if score_num > 0 else f'<span class="badge badge-success">{score_num}</span>' if score_num < 0 else f'<span class="badge badge-neutral">0</span>'
        except: badge = f'<span class="badge badge-neutral">{score}</span>'
        rows += f"<tr><td>{item}<br><span style='color:#888; font-size:11px;'>{note}</span></td><td style='text-align: right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª©</th><th style='text-align: right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def render_intelligence_distribution(current_prob):
    try:
        res = supabase.table("analysis_history").select("fake_prob").execute()
        if not res.data: return
        df = pd.DataFrame(res.data)
        base = alt.Chart(df).transform_density('fake_prob', as_=['fake_prob', 'density'], extent=[0, 100], bandwidth=5).mark_area(opacity=0.3, color='#888').encode(x=alt.X('fake_prob:Q', title='ê°€ì§œë‰´ìŠ¤ í™•ë¥  ë¶„í¬'), y=alt.Y('density:Q', title='ë°€ë„'))
        rule = alt.Chart(pd.DataFrame({'x': [current_prob]})).mark_rule(color='red', size=3).encode(x='x')
        st.altair_chart(base + rule, use_container_width=True)
    except: pass

# --- [Main Analysis Logic] ---
def run_forensic_main(url):
    st.session_state["debug_logs"] = []
    my_bar = st.progress(0, text="ë¶„ì„ ì—”ì§„ ê°€ë™ ì¤‘...")
    
    # 0. í•™ìŠµ ë°ì´í„° ë¡œë“œ
    db_count, dt, df = train_engine_wrapper()
    
    vid = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    if not vid: st.error("ì˜¬ë°”ë¥¸ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤."); return
    vid = vid.group(1)

    with yt_dlp.YoutubeDL({'quiet':True, 'skip_download':True}) as ydl:
        try:
            # 1. ë©”íƒ€ ë°ì´í„° ìˆ˜ì§‘
            info = ydl.extract_info(url, download=False)
            meta = {
                "ì œëª©": info.get('title'),
                "ì±„ë„ëª…": info.get('uploader'),
                "ì¡°íšŒìˆ˜": info.get('view_count', 0),
                "ëŒ“ê¸€ìˆ˜": info.get('comment_count', 0),
                "ì¹´í…Œê³ ë¦¬": ", ".join(info.get('categories', [])),
                "í•´ì‹œíƒœê·¸": ", ".join(info.get('tags', [])[:5])
            }
            
            my_bar.progress(20, "ì˜ìƒ ë‚´ìš© ë¶„ì„ ì¤‘...")
            trans, _ = fetch_transcript(info)
            full_text = trans if trans else info.get('description', '')
            summary = full_text[:800] + "..."
            
            my_bar.progress(40, "í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
            queries, _ = get_keywords(meta['ì œëª©'], full_text)
            
            news_items = []
            final_query = queries[0]
            for q in queries:
                items = fetch_news(q)
                if items: news_items = items; final_query = q; break
            
            my_bar.progress(60, "íŒ©íŠ¸ì²´í¬ ëŒ€ì¡° ë¶„ì„ ì¤‘...")
            # [ìˆ˜ì •] 5ê°œê¹Œì§€ ê²€ì¦
            news_ev = []; max_match = 0
            for item in news_items[:5]:
                s, r, src, r_url = verify_news(summary, item['link'], item['title'])
                if s > max_match: max_match = s
                icon = "ğŸŸ¢" if s>=80 else "ğŸŸ¡" if s>=60 else "ğŸ”´"
                news_ev.append({"ë‰´ìŠ¤ ì œëª©":item['title'], "ì¼ì¹˜ë„":f"{icon} {s}%", "ìµœì¢… ì ìˆ˜":s, "ë¶„ì„ ê·¼ê±°":r, "ë¹„ê³ ":src, "ì›ë¬¸":r_url})
            
            cmts = fetch_comments(vid)
            top_kw, rel_score, rel_msg = analyze_comments(cmts, full_text)
            red_cnt, _ = check_red_flags(cmts)
            
            ts, fs = vector_engine.analyze(final_query + " " + meta['ì œëª©'])
            t_impact, f_impact = int(ts*30)*-1, int(fs*30)
            
            news_score = -40 if max_match>=80 else -15 if max_match>=70 else 10 if max_match>=60 else 30
            if not news_ev: news_score = 0
            if check_official(meta['ì±„ë„ëª…']): news_score = -50
            
            agitation = count_agitation(meta['ì œëª©'])
            bait = 10 if agitation > 0 else -5
            
            base_score = 50 + t_impact + f_impact + news_score + min(20, red_cnt*3) + bait
            
            my_bar.progress(80, "AI ìµœì¢… íŒê²° ì¤‘...")
            ai_score, ai_reason = judge_final(meta['ì œëª©'], full_text, news_ev)
            
            final_prob = max(1, min(99, int(base_score*WEIGHT_ALGO + ai_score*WEIGHT_AI)))
            
            # [ì¶”ê°€] ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
            risk_text, _ = determine_risk_level(final_prob)
            final_summary = generate_comprehensive_summary(meta['ì œëª©'], final_prob, news_ev, red_cnt, ai_reason, risk_text)

            score_bd = [
                ["ê¸°ë³¸ ì ìˆ˜", 50, "Base Score"],
                ["ì§„ì‹¤ ë°ì´í„° ìœ ì‚¬ë„", t_impact, "Truth Corpus Similarity"],
                ["ê°€ì§œ ë°ì´í„° ìœ ì‚¬ë„", f_impact, "Fake Corpus Similarity"],
                ["ë‰´ìŠ¤ íŒ©íŠ¸ì²´í¬", news_score, "Journalism Match"],
                ["ì—¬ë¡  ë° ì–´ê·¸ë¡œ", min(20, red_cnt*3) + bait, "Sentiment & Clickbait"],
                ["AI íŒê²° (ê°€ì¤‘ì¹˜)", ai_score, "LLM Judge"]
            ]
            
            report = {
                "meta": meta, "summary": summary, "query_list": queries, "query": final_query,
                "score_breakdown": score_bd, "news_evidence": news_ev,
                "cmt_count": len(cmts), "cmt_rel": f"{rel_score}% ({rel_msg})", "red_cnt": red_cnt, "top_cmt_kw": top_kw,
                "ai_reason": ai_reason, "ts": ts, "fs": fs,
                "final_summary": final_summary # ì €ì¥
            }
            
            save_db(meta['ì±„ë„ëª…'], meta['ì œëª©'], final_prob, url, final_query, report)
            my_bar.empty()
            render_report_full_ui(final_prob, db_count, meta['ì œëª©'], meta['ì±„ë„ëª…'], report, is_cached=False)
            
        except Exception as e: st.error(f"Error: {e}")

def train_engine_wrapper():
    try:
        res_t = supabase.table("analysis_history").select("video_title").lt("fake_prob", 40).execute()
        res_f = supabase.table("analysis_history").select("video_title").gt("fake_prob", 60).execute()
        dt = [r['video_title'] for r in res_t.data] if res_t.data else []
        df = [r['video_title'] for r in res_f.data] if res_f.data else []
        vector_engine.train(STATIC_TRUTH + dt, STATIC_FAKE + df)
        return len(dt)+len(df), dt, df
    except:
        vector_engine.train(STATIC_TRUTH, STATIC_FAKE)
        return 0, [], []

# --- [B2B Report Logic] ---
def generate_b2b_report(df):
    if df.empty: return pd.DataFrame()
    df['fake_prob'] = pd.to_numeric(df['fake_prob'], errors='coerce').fillna(0)
    res = []
    for ch, g in df.groupby('channel_name'):
        avg = g['fake_prob'].mean()
        # í‚¤ì›Œë“œ flatten
        kws = []
        for k in g['keywords']:
            if isinstance(k, list): kws.extend([str(x) for x in k])
            elif k: kws.append(str(k))
        tokens = re.findall(r'[ê°€-í£]{2,}', " ".join(kws))
        target = ", ".join([t[0] for t in Counter(tokens).most_common(3)])
        grade = "â›” BLACKLIST" if avg>=60 else "âš ï¸ CAUTION" if avg>=40 else "âœ… SAFE"
        res.append({"Channel":ch, "Grade":grade, "Avg Risk":f"{int(avg)}%", "Videos":len(g), "Target":target})
    return pd.DataFrame(res).sort_values("Avg Risk", ascending=False)

# --- [Layout Main] ---
st.title("âš–ï¸ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° (Triple Engine)")

with st.container(border=True):
    with st.expander("â„¹ï¸ ì„œë¹„ìŠ¤ ì´ìš© ì•ˆë‚´ ë° ë©´ì±… ì¡°í•­ (Disclaimer)"):
        st.markdown("""
        ë³¸ ì„œë¹„ìŠ¤ëŠ” **ì¸ê³µì§€ëŠ¥(AI) ë° ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜**ìœ¼ë¡œ ì˜ìƒì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤. 
        **ë¶„ì„ ê²°ê³¼ëŠ” ì–´ë– í•œ ë²•ì  íš¨ë ¥ë„ ì—†ìœ¼ë©°, ìµœì¢… íŒë‹¨ê³¼ ì±…ì„ì€ ì „ì ìœ¼ë¡œ ì‚¬ìš©ì(ë‹¹ì‚¬ì)ì—ê²Œ ìˆìŠµë‹ˆë‹¤.**
        
        * **1st Line**: Mistral AI (Logic Analysis)
        * **2nd Line**: Google Gemini (Cross-Check)
        * **3rd Line**: Deep News Crawler (Fact Verification)
        """)
    agree = st.checkbox("ìœ„ ê³ ì§€ ë‚´ìš©ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ê²°ê³¼ì— ëŒ€í•œ ìµœì¢… ì±…ì„ì´ ë³¸ì¸ì—ê²Œ ìˆìŒì„ ë™ì˜í•©ë‹ˆë‹¤.")

url = st.text_input("ğŸ”— YouTube URL ì…ë ¥")
if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", use_container_width=True, disabled=not agree):
    if url: run_forensic_main(url)
    else: st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")

# --- [Bottom Section] ---
st.divider()
st.subheader("ğŸ—‚ï¸ DB History")

if st.session_state["is_admin"]:
    st.caption("âœ… ê´€ë¦¬ì ëª¨ë“œ: ì‚­ì œ ê°€ëŠ¥")
else:
    st.caption("ğŸ”’ ë·°ì–´ ëª¨ë“œ: ì¡°íšŒë§Œ ê°€ëŠ¥")

try:
    response = supabase.table("analysis_history").select("*").order("id", desc=True).execute()
    data = response.data
    
    if not data:
        st.info("ğŸ“­ ì €ì¥ëœ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df_hist = pd.DataFrame(data)
        
        if st.session_state["is_admin"]:
            if "Delete" not in df_hist.columns:
                df_hist.insert(0, "Delete", False)
            
            edited_df = st.data_editor(
                df_hist,
                hide_index=True,
                use_container_width=True,
                column_config={
                    "Delete": st.column_config.CheckboxColumn("ì‚­ì œ", help="ì²´í¬ í›„ ì‚­ì œ ë²„íŠ¼ í´ë¦­", default=False),
                    "fake_prob": st.column_config.NumberColumn("ê°€ì§œ í™•ë¥ ", format="%d%%"),
                    "video_url": st.column_config.LinkColumn("URL"),
                    "detail_json": None 
                },
                disabled=["id", "analysis_date", "channel_name", "video_title", "fake_prob", "keywords", "video_url"]
            )
            
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì˜êµ¬ ì‚­ì œ", type="primary"):
                to_delete = edited_df[edited_df['Delete'] == True]
                if not to_delete.empty:
                    for index, row in to_delete.iterrows():
                        supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                    st.success(f"{len(to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.warning("ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.dataframe(
                df_hist[['analysis_date','channel_name','video_title','fake_prob']], 
                use_container_width=True, 
                hide_index=True
            )
except Exception as e:
    st.error(f"âŒ DB ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

st.divider()
with st.expander("ğŸ” ê´€ë¦¬ì (Admin & B2B Report)"):
    if st.session_state["is_admin"]:
        st.success("Admin Logged In")
        if st.button("ğŸ“Š B2B ë¦¬í¬íŠ¸ ìƒì„±"):
            try:
                rpt = generate_b2b_report(pd.DataFrame(data))
                if not rpt.empty:
                    st.dataframe(rpt, use_container_width=True)
                    st.download_button("ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", rpt.to_csv().encode('utf-8-sig'), "b2b_report.csv", "text/csv")
            except: st.error("ë°ì´í„° ë¶€ì¡±")
        
        st.write("ğŸ“œ System Logs")
        st.text_area("Logs", "\n".join(st.session_state["debug_logs"]), height=200)
        
        if st.button("Logout"): st.session_state["is_admin"]=False; st.rerun()
    else:
        pwd = st.text_input("Password", type="password")
        if st.button("Login"):
            if pwd == ADMIN_PASSWORD: st.session_state["is_admin"]=True; st.rerun()
            else: st.error("Wrong Password")
