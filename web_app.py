import streamlit as st
from supabase import create_client, Client
import re
import requests
import time
import random
import math
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from openai import OpenAI
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
import altair as alt
import json
from bs4 import BeautifulSoup

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° v99.4", layout="wide", page_icon="ğŸ›¡ï¸")

# --- [2. ê¸€ë¡œë²Œ ìƒìˆ˜ ì •ì˜] ---
STATIC_TRUTH_CORPUS = ["ë°•ë‚˜ë˜ ìœ„ì¥ì „ì… ë¬´í˜ì˜", "ì„ì˜ì›… ì•”í‘œ ëŒ€ì‘", "ì •í¬ì› ì €ì†ë…¸í™”", "ëŒ€ì „ ì¶©ë‚¨ í†µí•©", "ì„ ê±° ì¶œë§ˆ ì„ ì–¸"]
STATIC_FAKE_CORPUS = ["ì¶©ê²© í­ë¡œ ê²½ì•…", "ê¸´ê¸‰ ì†ë³´ ì†Œë¦„", "ì¶©ê²© ë°œì–¸ ë…¼ë€", "êµ¬ì† ì˜ì¥ ë°œë¶€", "ì˜ìƒ ìœ ì¶œ", "ê³„ì‹œ ì˜ˆì–¸", "ì‚¬í˜• ì§‘í–‰", "ìœ„ë…ì„¤"]
WEIGHT_ALGO = 0.6
WEIGHT_AI = 0.4
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']

if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False
if "debug_logs" not in st.session_state:
    st.session_state["debug_logs"] = []

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    GOOGLE_API_KEY_A = st.secrets["GOOGLE_API_KEY_A"]
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
except Exception as e:
    st.error(f"âŒ í•„ìˆ˜ í‚¤ ì„¤ì • ëˆ„ë½: {e}")
    st.stop()

# Mistral í´ë¼ì´ì–¸íŠ¸
mistral_client = OpenAI(api_key=MISTRAL_API_KEY, base_url="https://api.mistral.ai/v1")

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase = init_supabase()

# --- [3. ìœ í‹¸ë¦¬í‹° & íŒŒì„œ] ---
def parse_ai_json(text):
    try:
        parsed = json.loads(text)
    except:
        try:
            text = re.sub(r'```json\s*', '', text).replace('```', '')
            match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
            if match: parsed = json.loads(match.group(1))
            else: return None
        except: return None
    if isinstance(parsed, list):
        return parsed[0] if len(parsed) > 0 and isinstance(parsed[0], dict) else None
    return parsed if isinstance(parsed, dict) else None

def safe_int_convert(val, default=50):
    try:
        if isinstance(val, dict): val = list(val.values())[0]
        return int(float(val))
    except: return default

def extract_video_id(url):
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return match.group(1) if match else None

# --- [4. AI ëª¨ë¸ ì—”ì§„] ---
def get_gemini_search_keywords(title, transcript):
    genai.configure(api_key=GOOGLE_API_KEY_A)
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"Fact-Check Investigator. Title: {title}. Transcript: {transcript[:10000]}. Extract ONE Korean news search query. String Only."
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except: return title

def call_mistral_judge(prompt, is_json=True):
    try:
        response = mistral_client.chat.completions.create(
            model="mistral-large-latest",
            messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íŒ©íŠ¸ì²´í¬ íŒì‚¬ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€(ì´ìœ  í¬í•¨)ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                      {"role": "user", "content": prompt}],
            response_format={"type": "json_object"} if is_json else None,
            temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        st.session_state["debug_logs"].append(f"âŒ Mistral Error: {e}")
        return None

# --- [5. VectorEngine] ---
class VectorEngine:
    def __init__(self):
        self.vocab = set()
        self.truth_vectors = []
        self.fake_vectors = []
    def tokenize(self, text): return re.findall(r'[ê°€-í£]{2,}', text)
    def train(self, truth, fake):
        for t in truth + fake: self.vocab.update(self.tokenize(t))
        self.vocab = sorted(list(self.vocab))
        self.truth_vectors = [self.text_to_vector(t) for t in truth]
        self.fake_vectors = [self.text_to_vector(t) for t in fake]
    def text_to_vector(self, text, vocabulary=None):
        target_vocab = vocabulary if vocabulary else self.vocab
        c = Counter(self.tokenize(text))
        return [c[w] for w in target_vocab]
    def cosine_similarity(self, v1, v2):
        dot = sum(a*b for a,b in zip(v1,v2))
        mag = math.sqrt(sum(a*a for a in v1)) * math.sqrt(sum(b*b for b in v2))
        return dot/mag if mag>0 else 0
    def analyze_position(self, query):
        if not self.vocab: return 0, 0
        qv = self.text_to_vector(query)
        mt = max([self.cosine_similarity(qv, v) for v in self.truth_vectors] or [0])
        mf = max([self.cosine_similarity(qv, v) for v in self.fake_vectors] or [0])
        return mt, mf

vector_engine = VectorEngine()

# --- [6. UI ì»´í¬ë„ŒíŠ¸ ë³µêµ¬] ---
def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border-spacing: 0; border: 1px solid #e0e0e0; border-radius: 8px; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; color: #495057; font-weight: bold; padding: 12px 15px; text-align: left; border-bottom: 1px solid #e0e0e0; } table.score-table td { padding: 12px 15px; border-bottom: 1px solid #f0f0f0; color: #333; } .badge { padding: 4px 8px; border-radius: 6px; font-weight: 700; font-size: 11px; display: inline-block; text-align: center; min-width: 45px; } .badge-danger { background-color: #ffebee; color: #d32f2f; } .badge-success { background-color: #e8f5e9; color: #2e7d32; } .badge-neutral { background-color: #f5f5f5; color: #757575; border: 1px solid #e0e0e0; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            score_num = int(score)
            badge = f'<span class="badge badge-danger">+{score_num}</span>' if score_num > 0 else f'<span class="badge badge-success">{score_num}</span>' if score_num < 0 else f'<span class="badge badge-neutral">0</span>'
        except: badge = f'<span class="badge badge-neutral">{score}</span>'
        rows += f"<tr><td>{item}<br><span style='color:#888; font-size:11px;'>{note}</span></td><td style='text-align: right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª© (Score Breakdown)</th><th style='text-align: right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def colored_progress_bar(label, percent, color):
    st.markdown(f"""<div style="margin-bottom: 10px;"><div style="display: flex; justify-content: space-between; margin-bottom: 3px;"><span style="font-size: 13px; font-weight: 600; color: #555;">{label}</span><span style="font-size: 13px; font-weight: 700; color: {color};">{round(percent * 100, 1)}%</span></div><div style="background-color: #eee; border-radius: 5px; height: 8px; width: 100%;"><div style="background-color: {color}; height: 8px; width: {percent * 100}%; border-radius: 5px;"></div></div></div>""", unsafe_allow_html=True)

def render_intelligence_distribution(current_prob):
    try:
        res = supabase.table("analysis_history").select("fake_prob").execute()
        if not res.data: return
        df = pd.DataFrame(res.data)
        base = alt.Chart(df).transform_density('fake_prob', as_=['fake_prob', 'density'], extent=[0, 100], bandwidth=5).mark_area(opacity=0.3, color='#888').encode(x=alt.X('fake_prob:Q', title='ê°€ì§œë‰´ìŠ¤ í™•ë¥  ë¶„í¬'), y=alt.Y('density:Q', title='ë°ì´í„° ë°€ë„'))
        rule = alt.Chart(pd.DataFrame({'x': [current_prob]})).mark_rule(color='blue', size=3).encode(x='x')
        st.altair_chart(base + rule, use_container_width=True)
    except: pass

# --- [7. ë¶„ì„ ì—”ì§„ ì„¸ë¶€ í•¨ìˆ˜] ---
def scrape_news_content_robust(url):
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        for t in soup(['script', 'style', 'nav', 'footer']): t.decompose()
        text = " ".join([p.get_text().strip() for p in soup.find_all('p') if len(p.get_text()) > 30])
        return (text[:4000], res.url) if len(text) > 100 else (None, res.url)
    except: return None, url

def deep_verify_news_mistral(video_summary, news_url, news_snippet):
    txt, real_url = scrape_news_content_robust(news_url)
    evidence = txt if txt else news_snippet
    prompt = f"""
    ë™ì˜ìƒ ìš”ì•½ë³¸ê³¼ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”.
    ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    [ë™ì˜ìƒ] {video_summary[:1500]}
    [ë‰´ìŠ¤] {evidence[:3000]}
    [íŒë‹¨ê¸°ì¤€] ì¼ì¹˜í•˜ë©´ 0-10ì , ë¶ˆì¼ì¹˜/í—ˆìœ„ë©´ 90-100ì .
    JSON í˜•ì‹: {{'score': int, 'reason': 'í•œê¸€ ì´ìœ '}}
    """
    res_text = call_mistral_judge(prompt)
    parsed = parse_ai_json(res_text)
    if parsed:
        s_val = safe_int_convert(parsed.get('score'))
        return s_val, parsed.get('reason', 'N/A'), "Full Article" if txt else "Snippet Only", evidence, real_url
    return 50, "ë¶„ì„ ì‹¤íŒ¨", "Error", "", news_url

def get_mistral_verdict_final(title, transcript, news_list):
    news_sum = "\n".join([f"- {n['ë‰´ìŠ¤ ì œëª©']} (ì¼ì¹˜ë„:{n['ìµœì¢… ì ìˆ˜']}, ê·¼ê±°:{n['ë¶„ì„ ê·¼ê±°']})" for n in news_list])
    prompt = f"""
    ìµœì¢… íŒê²°ì„ ë‚´ë¦¬ì„¸ìš”. ëª¨ë“  ë¶„ì„ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    ì˜ìƒ ì œëª©: {title}
    ë‰´ìŠ¤ ì¦ê±°: {news_sum}
    ì˜ìƒê³¼ ë‰´ìŠ¤ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ 0-20ì (ì§„ì‹¤), ë‹¤ë¥´ë©´ 80-100ì (ê°€ì§œ).
    JSON í˜•ì‹: {{'score': int, 'reason': '3ë¬¸ì¥ ì´ë‚´ì˜ í•œê¸€ íŒê²°ë¬¸'}}
    """
    res_text = call_mistral_judge(prompt)
    parsed = parse_ai_json(res_text)
    if parsed: 
        s_val = safe_int_convert(parsed.get('score'))
        return s_val, f"{parsed.get('reason')} (By Mistral Large)"
    return 50, "íŒê²° ì‹¤íŒ¨"

def fetch_real_transcript(info):
    try:
        subs = info.get('subtitles') or {}
        auto = info.get('automatic_captions') or {}
        merged = {**subs, **auto}
        if 'ko' in merged:
            for f in merged['ko']:
                if f['ext'] == 'vtt':
                    res = requests.get(f['url'])
                    return " ".join([l.strip() for l in res.text.splitlines() if l.strip() and '-->' not in l and '<' not in l]), "Success"
    except: pass
    return None, "Fail"

# --- [8. ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜ (ì™„ì „ ë³µêµ¬)] ---
def render_report_full_ui(prob, db_count, title, uploader, d, is_cached=False):
    if is_cached: st.success("ğŸ‰ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (Smart Cache)")

    st.subheader("ğŸ•µï¸ Dual-Engine Analysis Result")
    col_a, col_b, col_c = st.columns(3)
    col_a.metric("ìµœì¢… ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{prob}%")
    col_b.metric("AI íŒì •", "ğŸ”´ ìœ„í—˜" if prob > 60 else "ğŸŸ¢ ì•ˆì „" if prob < 30 else "ğŸŸ  ì£¼ì˜")
    col_c.metric("ì§€ì‹ ë…¸ë“œ", f"{db_count} Nodes")
    
    st.divider()
    st.subheader("ğŸ§  Intelligence Map")
    render_intelligence_distribution(prob)

    st.divider()
    col1, col2 = st.columns([1, 1.4])
    with col1:
        st.write("**[ì˜ìƒ ìƒì„¸ ì •ë³´]**")
        st.table(pd.DataFrame({"í•­ëª©": ["ì˜ìƒ ì œëª©", "ì±„ë„ëª…", "í•´ì‹œíƒœê·¸"], "ë‚´ìš©": [title, uploader, d.get('tags','ì—†ìŒ')]}))
        st.info(f"ğŸ¯ Investigator ì¶”ì¶œ ê²€ìƒ‰ì–´: {d.get('query', 'N/A')}")
        with st.container(border=True):
            st.markdown("ğŸ“ **ì˜ìƒ ë‚´ìš© ìš”ì•½**")
            st.write(d.get('summary','ë‚´ìš© ì—†ìŒ'))
        st.write("**[Score Breakdown]**")
        render_score_breakdown(d.get('score_breakdown', []))

    with col2:
        st.subheader("ğŸ“Š 5ëŒ€ ì •ë°€ ë¶„ì„ ì¦ê±°")
        st.markdown("**[ì¦ê±° 0] Semantic Vector Space (Internal DB)**")
        colored_progress_bar("âœ… ì§„ì‹¤ ì˜ì—­ ê·¼ì ‘ë„", d.get('ts', 0), "#2ecc71")
        colored_progress_bar("ğŸš¨ ê±°ì§“ ì˜ì—­ ê·¼ì ‘ë„", d.get('fs', 0), "#e74c3c")
        
        st.markdown("**[ì¦ê±° 1] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡° (Deep-Web Crawler)**")
        if d.get('news_evidence'):
            st.dataframe(pd.DataFrame(d.get('news_evidence', [])), column_config={"ì›ë¬¸": st.column_config.LinkColumn("ë§í¬", display_text="ğŸ”— ì´ë™")}, hide_index=True)
        else: st.warning("ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("**[ì¦ê±° 2] ì‹œì²­ì ì—¬ë¡  ë¶„ì„**")
        if d.get('comment_data'): st.table(pd.DataFrame(d['comment_data'], columns=["í•­ëª©", "ë‚´ìš©"]))
        
        st.markdown("**[ì¦ê±° 3] ìë§‰ ì„¸ë§Œí‹± ì‹¬ì¸µ ëŒ€ì¡°**")
        st.table(pd.DataFrame([["ì˜ìƒ ì£¼ìš” í‚¤ì›Œë“œ", d.get('top_kw','ë¶„ì„ë¨')], ["ì„ ë™ì„± ì§€ìˆ˜", f"{d.get('agitation',0)}íšŒ"]], columns=["í•­ëª©", "ë‚´ìš©"]))
        
        st.markdown("**[ì¦ê±° 4] AI ìµœì¢… ë¶„ì„ íŒë‹¨ (Judge Verdict)**")
        with st.container(border=True): st.write(f"âš–ï¸ **íŒê²°:** {d.get('ai_reason', 'N/A')}")

# --- [9. ë©”ì¸ ì‹¤í–‰ ë¡œì§] ---
def run_forensic_main(url):
    st.session_state["debug_logs"] = []
    vid = extract_video_id(url)
    if not vid: return st.error("ìœ íš¨í•˜ì§€ ì•Šì€ URL")

    # DB í•™ìŠµ
    res_t = supabase.table("analysis_history").select("video_title").lt("fake_prob", 40).execute()
    res_f = supabase.table("analysis_history").select("video_title").gt("fake_prob", 60).execute()
    dt, df = [r['video_title'] for r in res_t.data], [r['video_title'] for r in res_f.data]
    vector_engine.train(STATIC_TRUTH_CORPUS + dt, STATIC_FAKE_CORPUS + df)
    db_count = len(dt) + len(df)

    # ìºì‹œ ì²´í¬
    cached_res = supabase.table("analysis_history").select("*").ilike("video_url", f"%{vid}%").order("id", desc=True).limit(1).execute()
    if cached_res.data:
        c = cached_res.data[0]
        try:
            d = json.loads(c.get('detail_json', '{}'))
            render_report_full_ui(c['fake_prob'], db_count, c['video_title'], c['channel_name'], d, is_cached=True)
            return
        except: pass

    my_bar = st.progress(0, text="ë¶„ì„ ì‹œì‘...")
    with yt_dlp.YoutubeDL({'quiet': True, 'skip_download': True}) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            title, uploader, desc = info.get('title',''), info.get('uploader',''), info.get('description','')
            tags = info.get('tags', [])
            
            my_bar.progress(10, "ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            trans, _ = fetch_real_transcript(info)
            full_text = trans if trans else desc
            summary = full_text[:800] + "..."
            
            my_bar.progress(30, "AI ìˆ˜ì‚¬ê´€ ê°€ë™ ì¤‘...")
            query = get_gemini_search_keywords(title, full_text)
            
            my_bar.progress(50, "ë‰´ìŠ¤ í¬ë¡¤ë§ ì§„í–‰ ì¤‘...")
            rss = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR"
            items = re.findall(r'<item>(.*?)</item>', requests.get(rss).text, re.DOTALL)[:3]
            news_ev = []; max_match = 0
            for i in items:
                nt = re.search(r'<title>(.*?)</title>', i).group(1).replace("<![CDATA[", "").replace("]]>", "")
                nl = re.search(r'<link>(.*?)</link>', i).group(1)
                score, reason, src, _, real_url = deep_verify_news_mistral(summary, nl, "")
                if score > max_match: max_match = score
                news_ev.append({"ë‰´ìŠ¤ ì œëª©": nt, "ì¼ì¹˜ë„": f"{score}%", "ìµœì¢… ì ìˆ˜": score, "ë¶„ì„ ê·¼ê±°": reason, "ì›ë¬¸": real_url, "ë¹„ê³ ": src})

            ts, fs = vector_engine.analyze_position(query + " " + title)
            t_impact, f_impact = int(ts*30)*-1, int(fs*30)
            news_penalty = -30 if max_match <= 20 else (30 if max_match >= 80 else 0)
            
            my_bar.progress(85, "AI ìµœì¢… íŒê²° ì¤‘...")
            ai_score, ai_reason = get_mistral_verdict_final(title, full_text, news_ev)
            
            final_prob = max(1, min(99, int((50 + t_impact + f_impact + news_penalty)*WEIGHT_ALGO + ai_score*WEIGHT_AI)))
            
            score_breakdown = [["ê¸°ë³¸ ì ìˆ˜", 50, "ì¤‘ë¦½ ì‹œì‘"], ["ì§„ì‹¤ DB ë§¤ì¹­", t_impact, "ë‚´ë¶€ ë°ì´í„°"], ["ê±°ì§“ íŒ¨í„´ ë§¤ì¹­", f_impact, "ë‚´ë¶€ ë°ì´í„°"], ["ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_penalty, "í¬ë¡¤ë§ ê²°ê³¼"], ["AI íŒê²° ì ìˆ˜", ai_score, "Mistral íŒê²°"]]
            
            report = {
                "summary": summary, "news_evidence": news_ev, "ai_score": ai_score, "ai_reason": ai_reason,
                "score_breakdown": score_breakdown, "ts": ts, "fs": fs, "query": query, "tags": ", ".join(tags),
                "top_kw": "ë¶„ì„ë¨", "agitation": 1, "comment_data": [["ë¶„ì„ ìƒíƒœ", "ì™„ë£Œ"]]
            }
            
            supabase.table("analysis_history").insert({"channel_name": uploader, "video_title": title, "fake_prob": final_prob, "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "video_url": url, "keywords": query, "detail_json": json.dumps(report, ensure_ascii=False)}).execute()
            my_bar.empty()
            render_report_full_ui(final_prob, db_count, title, uploader, report)
        except Exception as e: st.error(f"ì˜¤ë¥˜: {e}")

# --- [10. UI ë ˆì´ì•„ì›ƒ] ---
st.title("âš–ï¸ Fact-Check Center v99.4")

with st.container(border=True):
    st.markdown("### ğŸ›¡ï¸ ë²•ì  ê³ ì§€ ë° ì±…ì„ í•œê³„ (Disclaimer)\në³¸ ì„œë¹„ìŠ¤ëŠ” **ì¸ê³µì§€ëŠ¥(AI) ë° ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜**ìœ¼ë¡œ ì˜ìƒì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤. \në¶„ì„ ê²°ê³¼ëŠ” ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©°, ìµœì¢… íŒë‹¨ì˜ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("* **Engine A (Investigator)**: Gemini 1.5 Flash (í‚¤ì›Œë“œ ì¶”ì¶œ)\n* **Engine B (Judge)**: Mistral Large 2 (í•œê¸€ ë³¸ë¬¸ ë¶„ì„ ë° íŒê²°)")
    agree = st.checkbox("ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ì´ì— ë™ì˜í•©ë‹ˆë‹¤. (ë™ì˜ ì‹œ ë¶„ì„ ë²„íŠ¼ í™œì„±í™”)")

url_input = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL")
if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", disabled=not agree, use_container_width=True):
    if url_input: run_forensic_main(url_input)

st.divider()
st.subheader("ğŸ—‚ï¸ í•™ìŠµ ë°ì´í„° ê´€ë¦¬ (Cloud Knowledge Base)")
try:
    resp = supabase.table("analysis_history").select("*").order("id", desc=True).limit(15).execute()
    df_h = pd.DataFrame(resp.data)
    if not df_h.empty:
        if st.session_state["is_admin"]:
            df_h['Delete'] = False
            edited = st.data_editor(df_h[['Delete', 'id', 'analysis_date', 'video_title', 'fake_prob']], hide_index=True, use_container_width=True)
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ", type="primary"):
                for _, row in edited[edited.Delete].iterrows():
                    supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                st.success("ì‚­ì œ ì™„ë£Œ")
                time.sleep(0.5)
                st.rerun()
        else: st.dataframe(df_h[['analysis_date', 'video_title', 'fake_prob']], use_container_width=True, hide_index=True)
except: pass

with st.expander("ğŸ” ê´€ë¦¬ì ì ‘ì†"):
    if not st.session_state["is_admin"]:
        if st.text_input("PW", type="password") == ADMIN_PASSWORD:
            st.session_state["is_admin"] = True
            st.rerun()
    else:
        st.write("ğŸ¤– í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ (Gemini A + Mistral B) ê°€ë™ ì¤‘")
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state["is_admin"] = False
            st.rerun()
