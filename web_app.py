import streamlit as st
import re
import requests
import time
import random
import math
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
from bs4 import BeautifulSoup
import altair as alt
import traceback

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="Fact-Check Center v54.1 (UI Restore)", layout="wide", page_icon="âš–ï¸")

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
except:
    st.error("âŒ í•„ìˆ˜ í‚¤(Secrets)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# DB ì—°ê²°
from supabase import create_client
@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

try:
    supabase = init_supabase()
except:
    st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    st.stop()

# --- [2. ê´€ë¦¬ì ì¸ì¦] ---
if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False

with st.sidebar:
    st.header("ğŸ›¡ï¸ ê´€ë¦¬ì ë©”ë‰´")
    with st.form("login_form"):
        password_input = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸", type="password")
        submit_button = st.form_submit_button("ë¡œê·¸ì¸")
        if submit_button:
            if password_input == ADMIN_PASSWORD:
                st.session_state["is_admin"] = True; st.rerun()
            else:
                st.session_state["is_admin"] = False; st.error("ë¹„ë°€ë²ˆí˜¸ ë¶ˆì¼ì¹˜")

    if st.session_state["is_admin"]:
        st.success("âœ… ê´€ë¦¬ì ì¸ì¦ë¨")
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state["is_admin"] = False; st.rerun()
    else:
        st.info("ë°ì´í„° ì‚­ì œëŠ” ê´€ë¦¬ìë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# --- [3. í•µì‹¬ ë¶„ì„ ì—”ì§„ (Pure Logic)] ---
VITAL_KEYWORDS = ['ìœ„ë…', 'ì‚¬ë§', 'ë³„ì„¸', 'êµ¬ì†', 'ì²´í¬', 'ê¸°ì†Œ', 'ì‹¤í˜•', 'ì‘ê¸‰ì‹¤', 'ì´í˜¼', 'ë¶ˆí™”', 'íŒŒê²½', 'ì¶©ê²©', 'ê²½ì•…', 'ì†ë³´', 'ê¸´ê¸‰', 'í­ë¡œ', 'ì–‘ì„±', 'í™•ì§„', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì¤‘íƒœ', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'í‡´ì§„', 'íƒ„í•µ', 'ë‚´ë€', 'ê°„ì²©']
VIP_ENTITIES = ['ìœ¤ì„ì—´', 'ëŒ€í†µë ¹', 'ì´ì¬ëª…', 'í•œë™í›ˆ', 'ê¹€ê±´í¬', 'ë¬¸ì¬ì¸', 'ë°•ê·¼í˜œ', 'ì´ëª…ë°•', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ', 'í‘¸í‹´', 'ì ¤ë ŒìŠ¤í‚¤', 'ì‹œì§„í•‘', 'ì •ì€', 'ì´ì¤€ì„', 'ì¡°êµ­', 'ì¶”ë¯¸ì• ', 'í™ì¤€í‘œ', 'ìœ ìŠ¹ë¯¼', 'ì•ˆì² ìˆ˜', 'ì†í¥ë¯¼', 'ì´ê°•ì¸', 'ê¹€ë¯¼ì¬', 'ë¥˜í˜„ì§„', 'ì¬ìš©', 'ì •ì˜ì„ ', 'ìµœíƒœì›', 'ë¥˜ì¤‘ì¼', 'ê°ë…', 'ì¡°ì„¸í˜¸', 'ìœ ì¬ì„', 'ì¥ë™ë¯¼', 'ìœ í˜¸ì •', 'ì´ì¬ë£¡', 'ì„ì„¸ë ¹']
CRITICAL_STATE_KEYWORDS = ['ë³„ê±°', 'ì´í˜¼', 'íŒŒê²½', 'ì‚¬ë§', 'ìœ„ë…', 'êµ¬ì†', 'ì²´í¬', 'ì‹¤í˜•', 'ë¶ˆí™”', 'í­ë¡œ', 'ì¶©ê²©', 'ë…¼ë€', 'ì¤‘íƒœ', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'íŒŒì‚°', 'ë¹šë”ë¯¸', 'ì „ê³¼', 'ê°ì˜¥', 'ê°„ì²©']
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']

def normalize_korean_word(word):
    josa_pattern = r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ë„|ë§Œ|í•œí…Œ|ì—ê²Œ|ì´ë‘|ê¹Œì§€|ë¶€í„°|ì¡°ì°¨|ë§ˆì €|ì´ë¼ê³ |ë¼ëŠ”|ë‹¤ëŠ”)$'
    if len(word) >= 2:
        return re.sub(josa_pattern, '', word)
    return word

def extract_meaningful_tokens(text):
    raw_tokens = re.findall(r'[ê°€-í£]{2,}', text)
    noise = ['ì¶©ê²©', 'ê²½ì•…', 'ì†ë³´', 'ê¸´ê¸‰', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì§€ê¸ˆ', 'ê²°êµ­', 'ë‰´ìŠ¤', 'ì˜ìƒ', 'ëŒ€ë¶€ë¶„', 'ì´ìœ ', 'ì™œ', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•˜ëŠ”', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ì§„ì§œ', 'ì •ë§', 'ë„ˆë¬´', 'ê·¸ëƒ¥', 'ì´ì œ', 'ì‚¬ì‹¤', 'êµ­ë¯¼', 'ìš°ë¦¬', 'ëŒ€í•œë¯¼êµ­', 'ì—¬ëŸ¬ë¶„', 'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë‚˜', 'ì†”ì§íˆ', 'ë¬´ìŠ¨', 'ì–´ë–¤']
    tokens = [normalize_korean_word(w) for w in raw_tokens]
    return [t for t in tokens if t not in noise and len(t) > 1]

def detect_subject_logic(title):
    for vip in VIP_ENTITIES:
        if vip in title: return vip
    honorifics = ['íšŒì¥', 'ì˜ì›', 'ëŒ€í‘œ', 'ëŒ€í†µë ¹', 'ì¥ê´€', 'ë°•ì‚¬', 'êµìˆ˜', 'ê°ë…', 'ì„ ìˆ˜', 'ì”¨', 'ë°°ìš°', 'ê°€ìˆ˜', 'ê°œê·¸ë§¨', 'ë°©ì†¡ì¸']
    title_split = title.split()
    for i, word in enumerate(title_split):
        for hon in honorifics:
            if hon in word and i > 0:
                prev_word = normalize_korean_word(title_split[i-1])
                if len(prev_word) > 1: return prev_word
    tokens = extract_meaningful_tokens(title)
    if tokens: return tokens[0]
    return ""

def generate_smart_query(title, transcript):
    subject = detect_subject_logic(title)
    t_tokens = set(extract_meaningful_tokens(title))
    tr_tokens = set(extract_meaningful_tokens(transcript[:1000]))
    common = t_tokens.intersection(tr_tokens)
    actions = [w for w in common if w != subject]
    action = max(actions, key=len) if actions else ""
    
    if not action:
        for crit in CRITICAL_STATE_KEYWORDS:
            if crit in title:
                action = crit
                break
    
    if subject and action: return f"{subject} {action}"
    elif subject: return f"{subject} {title.split()[-1]}"
    else: return " ".join(extract_meaningful_tokens(title)[:3])

# --- [4. UI ìœ í‹¸ë¦¬í‹° (ë³µêµ¬ë¨)] ---
def colored_progress_bar(label, percent, color):
    st.markdown(f"""<div style="margin-bottom: 10px;"><div style="display: flex; justify-content: space-between; margin-bottom: 3px;"><span style="font-size: 13px; font-weight: 600; color: #555;">{label}</span><span style="font-size: 13px; font-weight: 700; color: {color};">{round(percent * 100, 1)}%</span></div><div style="background-color: #eee; border-radius: 5px; height: 8px; width: 100%;"><div style="background-color: {color}; height: 8px; width: {percent * 100}%; border-radius: 5px;"></div></div></div>""", unsafe_allow_html=True)

def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border-spacing: 0; border: 1px solid #e0e0e0; border-radius: 8px; overflow: hidden; font-family: sans-serif; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; color: #495057; font-weight: bold; padding: 12px 15px; text-align: left; border-bottom: 1px solid #e0e0e0; } table.score-table td { padding: 12px 15px; border-bottom: 1px solid #f0f0f0; color: #333; } table.score-table tr:last-child td { border-bottom: none; } .badge { padding: 4px 8px; border-radius: 6px; font-weight: 700; font-size: 11px; display: inline-block; text-align: center; min-width: 45px; } .badge-danger { background-color: #ffebee; color: #d32f2f; } .badge-success { background-color: #e8f5e9; color: #2e7d32; } .badge-neutral { background-color: #f5f5f5; color: #757575; border: 1px solid #e0e0e0; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            score_num = int(score)
            badge = f'<span class="badge badge-danger">+{score_num}</span>' if score_num > 0 else f'<span class="badge badge-success">{score_num}</span>' if score_num < 0 else f'<span class="badge badge-neutral">0</span>'
        except: badge = f'<span class="badge badge-neutral">{score}</span>'
        rows += f"<tr><td>{item}<br><span style='color:#888; font-size:11px;'>{note}</span></td><td style='text-align: right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª© (Silent Echo Protocol)</th><th style='text-align: right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def witty_loading_sequence(total):
    messages = [
        f"ğŸ§  [Intelligence Level: {total}] ì§‘ë‹¨ ì§€ì„± ë¡œë“œ ì¤‘...",
        "ğŸ“¡ ì˜ìƒ ë°ì´í„° ì •ë°€ ì¶”ì¶œ ì¤‘...",
        "ğŸ” Pure Logic Engine ë¬¸ë§¥ ë¶„ì„ ì¤‘...", 
        "ğŸš€ ìœ„ì„±ì´ ìœ íŠœë¸Œ ë³¸ì‚¬ ìƒê³µì„ ì§€ë‚˜ê°€ëŠ” ì¤‘..."
    ]
    with st.status("ğŸ•µï¸ Context Merger v54.1 ê°€ë™ ì¤‘...", expanded=True) as status:
        for msg in messages: st.write(msg); time.sleep(0.5)
        st.write("âœ… ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!"); status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

def get_total_intelligence():
    try:
        count = supabase.table("analysis_history").select("id", count="exact").execute().count
        return count if count else 0
    except: return 0

# --- [5. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜] ---
def fetch_real_transcript(info):
    try:
        url = None
        for key in ['subtitles', 'automatic_captions']:
            if key in info and 'ko' in info[key]:
                for fmt in info[key]['ko']:
                    if fmt['ext'] == 'vtt': url = fmt['url']; break
            if url: break
        if url:
            res = requests.get(url)
            if res.status_code == 200 and "#EXTM3U" not in res.text:
                clean = []
                for line in res.text.splitlines():
                    if '-->' not in line and 'WEBVTT' not in line and line.strip():
                        t = re.sub(r'<[^>]+>', '', line).strip()
                        if t and t not in clean: clean.append(t)
                return " ".join(clean)
    except: pass
    return info.get('description', '')

def fetch_news_regex(query):
    news_res = []
    try:
        rss_url = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR&ceid=KR:ko"
        raw = requests.get(rss_url, timeout=5).text
        items = re.findall(r'<item>(.*?)</item>', raw, re.DOTALL)
        for item in items[:10]:
            t = re.search(r'<title>(.*?)</title>', item)
            nt = t.group(1).replace("<![CDATA[", "").replace("]]>", "") if t else ""
            news_res.append({'title': nt})
    except: pass
    return news_res

def calculate_match_score(news_title, query, video_title):
    q_tokens = set(extract_meaningful_tokens(query))
    n_tokens = set(extract_meaningful_tokens(news_title))
    match_cnt = len(q_tokens & n_tokens)
    score = 0
    if match_cnt >= 2: score = 80
    elif match_cnt == 1: score = 40
    for crit in CRITICAL_STATE_KEYWORDS:
        if crit in video_title and crit not in news_title: return 0
    return score

def summarize_text_simple(text):
    if not text: return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    return ". ".join([s.strip() for s in text.split('.')[:3] if s.strip()]) + "."

def save_analysis(channel, title, score, url, query):
    try:
        supabase.table("analysis_history").insert({
            "channel_name": channel, "video_title": title, "fake_prob": score,
            "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "video_url": url, "keywords": query
        }).execute()
    except: pass

def render_intelligence_distribution(current_prob):
    try:
        res = supabase.table("analysis_history").select("fake_prob").execute()
        if not res.data: return
        df = pd.DataFrame(res.data)
        base = alt.Chart(df).transform_density('fake_prob', as_=['fake_prob', 'density'], extent=[0, 100], bandwidth=5).mark_area(opacity=0.3, color='#888').encode(x=alt.X('fake_prob:Q', title='ê°€ì§œë‰´ìŠ¤ í™•ë¥  ë¶„í¬'), y=alt.Y('density:Q', title='ë°ì´í„° ë°€ë„'))
        rule = alt.Chart(pd.DataFrame({'x': [current_prob]})).mark_rule(color='blue', size=3).encode(x='x')
        st.altair_chart(base + rule, use_container_width=True)
        if current_prob > 60: st.error("âš ï¸ í˜„ì¬ ì˜ìƒì€ **'ê³ ìœ„í—˜êµ°'**ì— ì†í•©ë‹ˆë‹¤.")
        elif current_prob < 40: st.success("âœ… í˜„ì¬ ì˜ìƒì€ **'ì•ˆì „êµ°'**ì— ì†í•©ë‹ˆë‹¤.")
        else: st.warning("ğŸ”¸ í˜„ì¬ ì˜ìƒì€ **'ì¤‘ë¦½ êµ¬ê°„'**ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.")
    except: pass

# --- [6. ë©”ì¸ ì‹¤í–‰] ---
st.title("âš–ï¸ Triple-Evidence Intelligence Forensic v54.1")
with st.container(border=True):
    st.markdown("### ğŸ›¡ï¸ ë²•ì  ê³ ì§€ ë° ì±…ì„ í•œê³„ (Disclaimer)\në³¸ ì„œë¹„ìŠ¤ëŠ” **ì¸ê³µì§€ëŠ¥(AI) ë° ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜**ìœ¼ë¡œ ì˜ìƒì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤.\n* **ìµœì¢… íŒë‹¨ì˜ ì£¼ì²´:** ì •ë³´ì˜ ì§„ìœ„ ì—¬ë¶€ì— ëŒ€í•œ ìµœì¢…ì ì¸ íŒë‹¨ê³¼ ê·¸ì— ë”°ë¥¸ ì±…ì„ì€ **ì‚¬ìš©ì ë³¸ì¸**ì—ê²Œ ìˆìŠµë‹ˆë‹¤.")
    agree = st.checkbox("ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ì´ì— ë™ì˜í•©ë‹ˆë‹¤. (ë™ì˜ ì‹œ ë¶„ì„ ë²„íŠ¼ í™œì„±í™”)")

url_input = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL")
if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", use_container_width=True, disabled=not agree):
    if url_input:
        total_intelligence = get_total_intelligence()
        witty_loading_sequence(total_intelligence)
        
        with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
            try:
                info = ydl.extract_info(url_input, download=False)
                title = info.get('title', '')
                uploader = info.get('uploader', '')
                tags = info.get('tags', [])
                full_text = fetch_real_transcript(info)
                
                query = generate_smart_query(title, full_text)
                news_items = fetch_news_regex(query)
                
                max_match = 0
                verified_news = []
                for item in news_items:
                    s = calculate_match_score(item['title'], query, title)
                    if s > max_match: max_match = s
                    verified_news.append({'ë‰´ìŠ¤ ì œëª©': item['title'], 'ì¼ì¹˜ë„': f"{s}%"})
                
                # ì ìˆ˜ ë¡œì§
                score = 50
                breakdown = []
                
                is_silent = (len(news_items) == 0) or (max_match < 30)
                has_critical = any(k in title for k in CRITICAL_STATE_KEYWORDS)
                
                # 1. ë‰´ìŠ¤ ê²€ì¦
                news_diff = 0
                news_msg = ""
                if is_silent:
                    if has_critical: news_diff = 5; news_msg = "ë¯¸ê²€ì¦ ìœ„í—˜ ì£¼ì¥"
                    else: news_diff = 10; news_msg = "ì¦ê±° ë¶ˆì¶©ë¶„"
                else:
                    if max_match >= 80: news_diff = -45; news_msg = "ë‰´ìŠ¤ ê²€ì¦ ì™„ë£Œ"
                    elif max_match >= 40: news_diff = -20; news_msg = "ë¶€ë¶„ì  ì‚¬ì‹¤ í™•ì¸"
                    else: news_diff = 10; news_msg = "ë‚®ì€ ì—°ê´€ì„±"
                breakdown.append(["ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_diff, news_msg])
                
                # 2. ê³µì‹ ì±„ë„
                if any(o in uploader for o in OFFICIAL_CHANNELS):
                    breakdown.append(["ê³µì‹ ì–¸ë¡ ì‚¬", -50, "ì‹ ë¢°ë„ ë³´ì¥"])
                    
                # 3. ìê·¹ì„±
                agitation = sum(title.count(w) + full_text.count(w) for w in ['ì¶©ê²©','ê²½ì•…','í­ë¡œ','ì†ë³´','ê¸´ê¸‰'])
                if agitation > 0:
                    breakdown.append(["ìê·¹ì  í‘œí˜„", min(agitation*5, 20), f"ì„ ë™ í‚¤ì›Œë“œ {agitation}íšŒ"])
                
                final_score = 50 + sum(item[1] for item in breakdown)
                final_score = max(5, min(99, final_score))
                
                save_analysis(uploader, title, final_score, url_input, query)
                
                # --- UI ì¶œë ¥ ---
                st.subheader("ğŸ•µï¸ í•µì‹¬ ë¶„ì„ ì§€í‘œ (Key Indicators)")
                c1, c2, c3 = st.columns(3)
                with c1: st.metric("ìµœì¢… ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{final_score}%", delta=f"{final_score-50}")
                with c2:
                    icon = "ğŸŸ¢" if final_score < 30 else "ğŸ”´" if final_score > 60 else "ğŸŸ "
                    label = "ì•ˆì „" if final_score < 30 else "ìœ„í—˜" if final_score > 60 else "ì£¼ì˜"
                    st.metric("ì¢…í•© AI íŒì •", f"{icon} {label}")
                with c3: st.metric("AI Intelligence Level", f"{total_intelligence} Knowledge Nodes", delta="+1 Added")
                
                st.divider()
                col1, col2 = st.columns([1, 1.4])
                
                with col1:
                    st.write("**[ì˜ìƒ ìƒì„¸ ì •ë³´]**")
                    st.table(pd.DataFrame({"í•­ëª©": ["ì˜ìƒ ì œëª©", "ì±„ë„ëª…", "í•´ì‹œíƒœê·¸"], "ë‚´ìš©": [title, uploader, ", ".join(tags[:3])]}))
                    st.info(f"ğŸ¯ **AI ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ì–´**: {query}")
                    with st.container(border=True):
                        st.markdown("ğŸ“ **ì˜ìƒ ë‚´ìš© ìš”ì•½ (AI Abstract)**")
                        st.caption(summarize_text_simple(full_text))
                    
                    st.write("**[Score Breakdown]**")
                    render_score_breakdown([["ê¸°ë³¸ ìœ„í—˜ë„", 50, "Base Score"]] + breakdown)
                    
                with col2:
                    st.subheader("ğŸ“Š 5ëŒ€ ì •ë°€ ë¶„ì„ ì¦ê±°")
                    # Vector Simulation
                    vec_t = 0.8 if final_score < 40 else 0.2
                    vec_f = 0.8 if final_score > 60 else 0.2
                    colored_progress_bar("âœ… ì§„ì‹¤ ì˜ì—­ ê·¼ì ‘ë„", vec_t, "#2ecc71")
                    colored_progress_bar("ğŸš¨ ê±°ì§“ ì˜ì—­ ê·¼ì ‘ë„", vec_f, "#e74c3c")
                    
                    st.write("---")
                    st.markdown(f"**[ì¦ê±° 1] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡° (Query: {query})**")
                    if verified_news: st.table(pd.DataFrame(verified_news))
                    else: st.warning("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.subheader("ğŸ§  Intelligence Map: ë‚´ë¶€ ì§€ì‹ ë¶„í¬ë„")
                    render_intelligence_distribution(final_score)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.code(traceback.format_exc())

st.divider()
st.subheader("ğŸ—‚ï¸ í•™ìŠµ ë°ì´í„° ê´€ë¦¬ (Cloud Knowledge Base)")
try:
    response = supabase.table("analysis_history").select("*").order("id", desc=True).execute()
    df = pd.DataFrame(response.data)
except: df = pd.DataFrame()

if not df.empty:
    df['Delete'] = False
    cols = ['Delete', 'id', 'analysis_date', 'video_title', 'fake_prob', 'keywords']
    df = df[cols]
    if st.session_state.get("is_admin", False):
        edited_df = st.data_editor(df, column_config={"Delete": st.column_config.CheckboxColumn("ì„ íƒ ì‚­ì œ", default=False)}, disabled=["id", "analysis_date", "video_title", "keywords"], hide_index=True, use_container_width=True)
        to_delete = edited_df[edited_df.Delete]
        if not to_delete.empty:
            if st.button(f"ğŸ—‘ï¸ ì„ íƒí•œ {len(to_delete)}ê±´ì˜ ê¸°ë¡ ì˜êµ¬ ì‚­ì œ", type="primary"):
                try:
                    for index, row in to_delete.iterrows(): supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                    st.success("âœ… ì‚­ì œ ì™„ë£Œ!"); time.sleep(1); st.rerun()
                except Exception as e: st.error(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.dataframe(df.drop(columns=['Delete']), hide_index=True, use_container_width=True)
        st.info("ğŸ”’ ë°ì´í„° ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. (ê´€ë¦¬ì ë¡œê·¸ì¸ í•„ìš”)")
else: st.info("â˜ï¸ í´ë¼ìš°ë“œ DBì— ì €ì¥ëœ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
