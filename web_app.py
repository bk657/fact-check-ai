import streamlit as st
from supabase import create_client, Client
import re
import requests
import time
import random
import math
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from openai import OpenAI
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
import altair as alt
import json
from bs4 import BeautifulSoup

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ê°€ì§œë‰´ìŠ¤ íŒë…ê¸° v99.2", layout="wide", page_icon="âš–ï¸")

# --- [2. ê¸€ë¡œë²Œ ìƒìˆ˜ ì •ì˜] ---
STATIC_TRUTH_CORPUS = ["ë°•ë‚˜ë˜ ìœ„ì¥ì „ì… ë¬´í˜ì˜", "ì„ì˜ì›… ì•”í‘œ ëŒ€ì‘", "ì •í¬ì› ì €ì†ë…¸í™”", "ëŒ€ì „ ì¶©ë‚¨ í†µí•©", "ì„ ê±° ì¶œë§ˆ ì„ ì–¸"]
STATIC_FAKE_CORPUS = ["ì¶©ê²© í­ë¡œ ê²½ì•…", "ê¸´ê¸‰ ì†ë³´ ì†Œë¦„", "ì¶©ê²© ë°œì–¸ ë…¼ë€", "êµ¬ì† ì˜ì¥ ë°œë¶€", "ì˜ìƒ ìœ ì¶œ", "ê³„ì‹œ ì˜ˆì–¸", "ì‚¬í˜• ì§‘í–‰", "ìœ„ë…ì„¤"]
WEIGHT_ALGO = 0.6
WEIGHT_AI = 0.4
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„']

if "is_admin" not in st.session_state:
    st.session_state["is_admin"] = False
if "debug_logs" not in st.session_state:
    st.session_state["debug_logs"] = []

# ğŸŒŸ Secrets ë¡œë“œ
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
    GOOGLE_API_KEY_A = st.secrets["GOOGLE_API_KEY_A"]
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
except Exception as e:
    st.error(f"âŒ í•„ìˆ˜ í‚¤ ì„¤ì • ëˆ„ë½: {e}")
    st.stop()

# Mistral í´ë¼ì´ì–¸íŠ¸
mistral_client = OpenAI(api_key=MISTRAL_API_KEY, base_url="https://api.mistral.ai/v1")

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase = init_supabase()

# --- [3. ìœ í‹¸ë¦¬í‹° & íŒŒì„œ] ---
def parse_ai_json(text):
    try:
        parsed = json.loads(text)
    except:
        try:
            text = re.sub(r'```json\s*', '', text).replace('```', '')
            match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
            if match: parsed = json.loads(match.group(1))
            else: return None
        except: return None
    if isinstance(parsed, list):
        return parsed[0] if len(parsed) > 0 and isinstance(parsed[0], dict) else None
    return parsed if isinstance(parsed, dict) else None

def extract_video_id(url):
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return match.group(1) if match else None

# --- [4. AI ëª¨ë¸ ì—”ì§„] ---
def get_gemini_search_keywords(title, transcript):
    genai.configure(api_key=GOOGLE_API_KEY_A)
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"Fact-Check Investigator. Title: {title}. Transcript: {transcript[:10000]}. Extract ONE Korean news search query. String Only."
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except: return title

def call_mistral_judge(prompt, is_json=True):
    try:
        response = mistral_client.chat.completions.create(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"} if is_json else None,
            temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        st.session_state["debug_logs"].append(f"âŒ Mistral Error: {e}")
        return None

# --- [5. VectorEngine] ---
class VectorEngine:
    def __init__(self):
        self.vocab = set()
        self.truth_vectors = []
        self.fake_vectors = []
    def tokenize(self, text): return re.findall(r'[ê°€-í£]{2,}', text)
    def train(self, truth, fake):
        for t in truth + fake: self.vocab.update(self.tokenize(t))
        self.vocab = sorted(list(self.vocab))
        self.truth_vectors = [self.text_to_vector(t) for t in truth]
        self.fake_vectors = [self.text_to_vector(t) for t in fake]
    def text_to_vector(self, text, vocabulary=None):
        target_vocab = vocabulary if vocabulary else self.vocab
        c = Counter(self.tokenize(text))
        return [c[w] for w in target_vocab]
    def cosine_similarity(self, v1, v2):
        dot = sum(a*b for a,b in zip(v1,v2))
        mag = math.sqrt(sum(a*a for a in v1)) * math.sqrt(sum(b*b for b in v2))
        return dot/mag if mag>0 else 0
    def analyze_position(self, query):
        if not self.vocab: return 0, 0
        qv = self.text_to_vector(query)
        mt = max([self.cosine_similarity(qv, v) for v in self.truth_vectors] or [0])
        mf = max([self.cosine_similarity(qv, v) for v in self.fake_vectors] or [0])
        return mt, mf

vector_engine = VectorEngine()

# --- [6. ìƒì„¸ ë¶„ì„ í•¨ìˆ˜] ---
def scrape_news_content_robust(url):
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        for t in soup(['script', 'style', 'nav', 'footer']): t.decompose()
        text = " ".join([p.get_text().strip() for p in soup.find_all('p') if len(p.get_text()) > 30])
        return (text[:4000], res.url) if len(text) > 100 else (None, res.url)
    except: return None, url

def deep_verify_news_mistral(video_summary, news_url, news_snippet):
    txt, real_url = scrape_news_content_robust(news_url)
    evidence = txt if txt else news_snippet
    prompt = f"Video: {video_summary[:1500]}. News: {evidence[:3000]}. Match(0-10 Truth), Mismatch(90-100 Fake). JSON {{'score', 'reason'}}"
    res_text = call_mistral_judge(prompt)
    parsed = parse_ai_json(res_text)
    if parsed:
        # [í•µì‹¬ ìˆ˜ì •] score ê°’ì„ í™•ì‹¤í•˜ê²Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        return int(parsed.get('score', 50)), parsed.get('reason', 'N/A'), "Full" if txt else "Snippet", evidence, real_url
    return 50, "Error", "Error", "", news_url

def get_mistral_verdict_final(title, transcript, news_list):
    news_sum = "\n".join([f"- {n['ë‰´ìŠ¤ ì œëª©']} (Score:{n['ìµœì¢… ì ìˆ˜']}, Reason:{n['ë¶„ì„ ê·¼ê±°']})" for n in news_list])
    prompt = f"Judge Final Verdict. Title: {title}. News: {news_sum}. Match(0-20 Truth), Mismatch(80-100 Fake). JSON {{'score', 'reason'}}"
    res_text = call_mistral_judge(prompt)
    parsed = parse_ai_json(res_text)
    if parsed: return int(parsed.get('score', 50)), f"{parsed.get('reason')} (By Mistral Large)"
    return 50, "Judgment Failed"

def fetch_real_transcript(info):
    try:
        subs = info.get('subtitles') or {}
        auto = info.get('automatic_captions') or {}
        merged = {**subs, **auto}
        if 'ko' in merged:
            for f in merged['ko']:
                if f['ext'] == 'vtt':
                    res = requests.get(f['url'])
                    return " ".join([l.strip() for l in res.text.splitlines() if l.strip() and '-->' not in l and '<' not in l]), "Success"
    except: pass
    return None, "Fail"

# --- [7. UI ì»´í¬ë„ŒíŠ¸ ë³µêµ¬] ---
def render_score_breakdown(data_list):
    style = """<style>table.score-table { width: 100%; border-collapse: separate; border-spacing: 0; border: 1px solid #e0e0e0; border-radius: 8px; overflow: hidden; font-family: sans-serif; font-size: 14px; margin-top: 10px;} table.score-table th { background-color: #f8f9fa; color: #495057; font-weight: bold; padding: 12px 15px; text-align: left; border-bottom: 1px solid #e0e0e0; } table.score-table td { padding: 12px 15px; border-bottom: 1px solid #f0f0f0; color: #333; } .badge { padding: 4px 8px; border-radius: 6px; font-weight: 700; font-size: 11px; display: inline-block; text-align: center; min-width: 45px; } .badge-danger { background-color: #ffebee; color: #d32f2f; } .badge-success { background-color: #e8f5e9; color: #2e7d32; } .badge-neutral { background-color: #f5f5f5; color: #757575; border: 1px solid #e0e0e0; }</style>"""
    rows = ""
    for item, score, note in data_list:
        try:
            score_num = int(score)
            badge = f'<span class="badge badge-danger">+{score_num} (ê°€ì§œ ì˜ì‹¬)</span>' if score_num > 0 else f'<span class="badge badge-success">{score_num} (ì§„ì‹¤ ì…ì¦)</span>' if score_num < 0 else f'<span class="badge badge-neutral">0</span>'
        except: badge = f'<span class="badge badge-neutral">{score}</span>'
        rows += f"<tr><td>{item}<br><span style='color:#888; font-size:11px;'>{note}</span></td><td style='text-align: right;'>{badge}</td></tr>"
    st.markdown(f"{style}<table class='score-table'><thead><tr><th>ë¶„ì„ í•­ëª©</th><th style='text-align: right;'>ë³€ë™</th></tr></thead><tbody>{rows}</tbody></table>", unsafe_allow_html=True)

def colored_progress_bar(label, percent, color):
    st.markdown(f"""<div style="margin-bottom: 10px;"><div style="display: flex; justify-content: space-between; margin-bottom: 3px;"><span style="font-size: 13px; font-weight: 600; color: #555;">{label}</span><span style="font-size: 13px; font-weight: 700; color: {color};">{round(percent * 100, 1)}%</span></div><div style="background-color: #eee; border-radius: 5px; height: 8px; width: 100%;"><div style="background-color: {color}; height: 8px; width: {percent * 100}%; border-radius: 5px;"></div></div></div>""", unsafe_allow_html=True)

def render_report_full_ui(prob, db_count, title, uploader, d, is_cached=False):
    if is_cached: st.success("ğŸ‰ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (Smart Cache)")
    st.subheader("ğŸ•µï¸ Dual-Engine Analysis Result")
    col_a, col_b, col_c = st.columns(3)
    col_a.metric("ê°€ì§œë‰´ìŠ¤ í™•ë¥ ", f"{prob}%")
    col_b.metric("AI íŒì •", "ğŸ”´ ìœ„í—˜" if prob > 60 else "ğŸŸ¢ ì•ˆì „" if prob < 30 else "ğŸŸ  ì£¼ì˜")
    col_c.metric("ì§€ì‹ ë…¸ë“œ", f"{db_count} Nodes")
    st.divider()
    col1, col2 = st.columns([1, 1.4])
    with col1:
        st.write(f"**ì œëª©:** {title}\n**ì±„ë„:** {uploader}")
        st.info(f"ğŸ¯ ê²€ìƒ‰ì–´: {d.get('query', 'N/A')}")
        st.markdown("ğŸ“ **ë‚´ìš© ìš”ì•½**")
        st.write(d.get('summary','ë‚´ìš© ì—†ìŒ'))
        render_score_breakdown(d.get('score_breakdown', []))
    with col2:
        st.write("ğŸ“Š **5ëŒ€ ì •ë°€ ë¶„ì„ ì¦ê±°**")
        colored_progress_bar("âœ… ì§„ì‹¤ ì˜ì—­ ê·¼ì ‘ë„", d.get('ts', 0), "#2ecc71")
        colored_progress_bar("ğŸš¨ ê±°ì§“ ì˜ì—­ ê·¼ì ‘ë„", d.get('fs', 0), "#e74c3c")
        st.markdown("**[ì¦ê±° 1] ë‰´ìŠ¤ êµì°¨ ëŒ€ì¡° (Deep Crawling)**")
        st.dataframe(pd.DataFrame(d.get('news_evidence', [])), column_config={"ì›ë¬¸": st.column_config.LinkColumn("ë§í¬", display_text="ğŸ”— ì´ë™")}, hide_index=True)
        with st.container(border=True): st.write(f"âš–ï¸ **AI íŒê²°:** {d.get('ai_reason', 'N/A')}")

# --- [8. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜] ---
def run_forensic_main(url):
    vid = extract_video_id(url)
    if not vid: return st.error("URL ì˜¤ë¥˜")

    res_t = supabase.table("analysis_history").select("video_title").lt("fake_prob", 40).execute()
    res_f = supabase.table("analysis_history").select("video_title").gt("fake_prob", 60).execute()
    dt, df = [r['video_title'] for r in res_t.data], [r['video_title'] for r in res_f.data]
    vector_engine.train(STATIC_TRUTH_CORPUS + dt, STATIC_FAKE_CORPUS + df)
    db_count = len(dt) + len(df)

    cached_res = supabase.table("analysis_history").select("*").ilike("video_url", f"%{vid}%").order("id", desc=True).limit(1).execute()
    if cached_res.data:
        c = cached_res.data[0]
        try:
            d = json.loads(c.get('detail_json', '{}'))
            render_report_full_ui(c['fake_prob'], db_count, c['video_title'], c['channel_name'], d, is_cached=True)
            return
        except: pass

    my_bar = st.progress(0, text="ë¶„ì„ ì‹œì‘...")
    with yt_dlp.YoutubeDL({'quiet': True, 'skip_download': True}) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            title, uploader, desc = info.get('title',''), info.get('uploader',''), info.get('description','')
            trans, _ = fetch_real_transcript(info)
            full_text = trans if trans else desc
            query = get_gemini_search_keywords(title, full_text)
            
            rss = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR"
            items = re.findall(r'<item>(.*?)</item>', requests.get(rss).text, re.DOTALL)[:3]
            news_ev = []; max_match = 0
            for i in items:
                nt_match = re.search(r'<title>(.*?)</title>', i)
                nl_match = re.search(r'<link>(.*?)</link>', i)
                nd_match = re.search(r'<description>(.*?)</description>', i)
                if nt_match and nl_match:
                    nt = nt_match.group(1).replace("<![CDATA[", "").replace("]]>", "")
                    nl = nl_match.group(1)
                    nd = nd_match.group(1) if nd_match else ""
                    score, reason, src, _, real_url = deep_verify_news_mistral(full_text, nl, nd)
                    # [ì—ëŸ¬ ìˆ˜ì •] scoreë¥¼ intë¡œ í™•ì‹¤íˆ ë³€í™˜í•˜ì—¬ ë¹„êµ
                    s_val = int(score)
                    if s_val > max_match: max_match = s_val
                    news_ev.append({"ë‰´ìŠ¤ ì œëª©": nt, "ì¼ì¹˜ë„": f"{s_val}%", "ìµœì¢… ì ìˆ˜": s_val, "ë¶„ì„ ê·¼ê±°": reason, "ì›ë¬¸": real_url})

            ts, fs = vector_engine.analyze_position(query + " " + title)
            news_penalty = -30 if max_match <= 20 else (30 if max_match >= 80 else 0)
            ai_score, ai_reason = get_mistral_verdict_final(title, full_text, news_ev)
            final_prob = max(1, min(99, int((50 + (int(ts*30)*-1) + int(fs*30) + news_penalty)*WEIGHT_ALGO + ai_score*WEIGHT_AI)))
            
            report = {"summary": full_text[:500], "news_evidence": news_ev, "ai_score": ai_score, "ai_reason": ai_reason, "score_breakdown": [["ê¸°ë³¸ ì¤‘ë¦½ ì ìˆ˜", 50, "ëª¨ë“  ë¶„ì„ì€ 50ì ì—ì„œ ì‹œì‘"], ["ì§„ì‹¤ ë°ì´í„° ë§¥ë½", int(ts*30)*-1, "ë‚´ë¶€ DB ë§¤ì¹­"], ["ê°€ì§œ íŒ¨í„´ ë§¥ë½", int(fs*30), "ë‚´ë¶€ DB ë§¤ì¹­"], ["ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_penalty, "í¬ë¡¤ë§ ê²°ê³¼"], ["AI íŒê²° ì ìˆ˜", ai_score, "Mistral ìµœì¢… ì¶”ë¡ "]], "ts": ts, "fs": fs, "query": query}
            supabase.table("analysis_history").insert({"channel_name": uploader, "video_title": title, "fake_prob": final_prob, "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), "video_url": url, "keywords": query, "detail_json": json.dumps(report, ensure_ascii=False)}).execute()
            my_bar.empty()
            render_report_full_ui(final_prob, db_count, title, uploader, report)
        except Exception as e: st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

# --- [9. UI ë ˆì´ì•„ì›ƒ] ---
st.title("âš–ï¸ Fact-Check Center v99.2")

with st.container(border=True):
    st.markdown("### ğŸ›¡ï¸ ë²•ì  ê³ ì§€ ë° ì±…ì„ í•œê³„ (Disclaimer)\në³¸ ì„œë¹„ìŠ¤ëŠ” **ì¸ê³µì§€ëŠ¥(AI) ë° ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜**ìœ¼ë¡œ ì˜ìƒì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤. \në¶„ì„ ê²°ê³¼ëŠ” ë²•ì  íš¨ë ¥ì´ ì—†ìœ¼ë©°, ìµœì¢… íŒë‹¨ì˜ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("* **Engine A (Investigator)**: Gemini 1.5 Flash (í‚¤ì›Œë“œ ì¶”ì¶œ)\n* **Engine B (Judge)**: Mistral Large 2 (ë³¸ë¬¸ ë¶„ì„ ë° íŒê²°)")
    agree = st.checkbox("ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ì´ì— ë™ì˜í•©ë‹ˆë‹¤. (ë™ì˜ ì‹œ ë¶„ì„ ë²„íŠ¼ í™œì„±í™”)")

url_input = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL")
if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", disabled=not agree, use_container_width=True):
    if url_input: run_forensic_main(url_input)

st.divider()
st.subheader("ğŸ—‚ï¸ í•™ìŠµ ë°ì´í„° ê´€ë¦¬ (Cloud Knowledge Base)")
try:
    resp = supabase.table("analysis_history").select("*").order("id", desc=True).limit(20).execute()
    df_hist = pd.DataFrame(resp.data)
    if not df_hist.empty:
        if st.session_state["is_admin"]:
            df_hist['Delete'] = False
            edited = st.data_editor(df_hist[['Delete', 'id', 'analysis_date', 'video_title', 'fake_prob', 'keywords']], hide_index=True, use_container_width=True)
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ", type="primary"):
                for _, row in edited[edited.Delete].iterrows():
                    supabase.table("analysis_history").delete().eq("id", row['id']).execute()
                st.success("âœ… ì‚­ì œ ì™„ë£Œ ë° ëª©ë¡ ê°±ì‹ ")
                time.sleep(1)
                st.rerun()
        else: st.dataframe(df_hist[['analysis_date', 'video_title', 'fake_prob', 'keywords']], use_container_width=True, hide_index=True)
except: pass

with st.expander("ğŸ” ê´€ë¦¬ì ì ‘ì† (Admin Access)"):
    if not st.session_state["is_admin"]:
        if st.text_input("Admin Password", type="password") == ADMIN_PASSWORD:
            st.session_state["is_admin"] = True
            st.rerun()
    else:
        st.write(f"**ğŸ¤– ì—”ì§„ ìƒíƒœ:** Gemini(A) + Mistral(B) Active")
        if st.session_state["debug_logs"]:
            st.text_area("Debug Logs", "\n".join(st.session_state["debug_logs"]), height=250)
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state["is_admin"] = False
            st.rerun()
