import streamlit as st
import re
import requests
import time
import random
import math
from datetime import datetime
from collections import Counter
import yt_dlp
import pandas as pd
from bs4 import BeautifulSoup
import altair as alt
import traceback

# --- [1. ì‹œìŠ¤í…œ ì„¤ì •] ---
st.set_page_config(page_title="Fact-Check Center v54.0 (Masterpiece)", layout="wide", page_icon="âš–ï¸")

# ğŸŒŸ Secrets ë¡œë“œ (ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬)
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    ADMIN_PASSWORD = st.secrets["ADMIN_PASSWORD"]
except:
    st.error("âŒ í•„ìˆ˜ í‚¤(Secrets)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# DB ì—°ê²°
from supabase import create_client
@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

try:
    supabase = init_supabase()
except:
    st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    st.stop()

# --- [2. í•µì‹¬ ë¶„ì„ ì—”ì§„ (Pure Logic NLP)] ---
# ë¬´ê±°ìš´ AI ëŒ€ì‹  ì •êµí•œ ê·œì¹™ ê¸°ë°˜ ì—”ì§„ ì‚¬ìš©

VITAL_KEYWORDS = ['ìœ„ë…', 'ì‚¬ë§', 'ë³„ì„¸', 'êµ¬ì†', 'ì²´í¬', 'ê¸°ì†Œ', 'ì‹¤í˜•', 'ì‘ê¸‰ì‹¤', 'ì´í˜¼', 'ë¶ˆí™”', 'íŒŒê²½', 'ì¶©ê²©', 'ê²½ì•…', 'ì†ë³´', 'ê¸´ê¸‰', 'í­ë¡œ', 'ì–‘ì„±', 'í™•ì§„', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì¤‘íƒœ', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'í‡´ì§„', 'íƒ„í•µ', 'ë‚´ë€', 'ê°„ì²©']
VIP_ENTITIES = ['ìœ¤ì„ì—´', 'ëŒ€í†µë ¹', 'ì´ì¬ëª…', 'í•œë™í›ˆ', 'ê¹€ê±´í¬', 'ë¬¸ì¬ì¸', 'ë°•ê·¼í˜œ', 'ì´ëª…ë°•', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ', 'í‘¸í‹´', 'ì ¤ë ŒìŠ¤í‚¤', 'ì‹œì§„í•‘', 'ì •ì€', 'ì´ì¤€ì„', 'ì¡°êµ­', 'ì¶”ë¯¸ì• ', 'í™ì¤€í‘œ', 'ìœ ìŠ¹ë¯¼', 'ì•ˆì² ìˆ˜', 'ì†í¥ë¯¼', 'ì´ê°•ì¸', 'ê¹€ë¯¼ì¬', 'ë¥˜í˜„ì§„', 'ì¬ìš©', 'ì •ì˜ì„ ', 'ìµœíƒœì›', 'ë¥˜ì¤‘ì¼', 'ê°ë…', 'ì¡°ì„¸í˜¸', 'ìœ ì¬ì„', 'ì¥ë™ë¯¼', 'ìœ í˜¸ì •', 'ì´ì¬ë£¡', 'ì„ì„¸ë ¹']
CRITICAL_STATE_KEYWORDS = ['ë³„ê±°', 'ì´í˜¼', 'íŒŒê²½', 'ì‚¬ë§', 'ìœ„ë…', 'êµ¬ì†', 'ì²´í¬', 'ì‹¤í˜•', 'ë¶ˆí™”', 'í­ë¡œ', 'ì¶©ê²©', 'ë…¼ë€', 'ì¤‘íƒœ', 'ì‹¬ì •ì§€', 'ë‡Œì‚¬', 'ì••ìˆ˜ìˆ˜ìƒ‰', 'ì†Œí™˜', 'íŒŒì‚°', 'ë¹šë”ë¯¸', 'ì „ê³¼', 'ê°ì˜¥', 'ê°„ì²©']
OFFICIAL_CHANNELS = ['MBC', 'KBS', 'SBS', 'EBS', 'YTN', 'JTBC', 'TVCHOSUN', 'MBN', 'CHANNEL A', 'OBS', 'ì±„ë„A', 'TVì¡°ì„ ', 'ì—°í•©ë‰´ìŠ¤', 'YONHAP', 'í•œê²¨ë ˆ', 'ê²½í–¥', 'ì¡°ì„ ', 'ì¤‘ì•™', 'ë™ì•„', 'JTBC News', 'SBS ë‰´ìŠ¤', 'KBS News', 'MBCNEWS']

def normalize_korean_word(word):
    """í•œêµ­ì–´ ì¡°ì‚¬ ì œê±° (Regex)"""
    # ì€/ëŠ”/ì´/ê°€/ì„/ë¥¼/ì˜/ì—/ì—ì„œ/ë¡œ/ìœ¼ë¡œ/ì™€/ê³¼/ë„/ë§Œ...
    josa_pattern = r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ë„|ë§Œ|í•œí…Œ|ì—ê²Œ|ì´ë‘|ê¹Œì§€|ë¶€í„°|ì¡°ì°¨|ë§ˆì €|ì´ë¼ê³ |ë¼ëŠ”|ë‹¤ëŠ”)$'
    if len(word) >= 2:
        return re.sub(josa_pattern, '', word)
    return word

def extract_meaningful_tokens(text):
    """ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ"""
    # í•œê¸€ë§Œ ì¶”ì¶œ
    raw_tokens = re.findall(r'[ê°€-í£]{2,}', text)
    # ë¶ˆìš©ì–´(Stopwords)
    noise = ['ì¶©ê²©', 'ê²½ì•…', 'ì†ë³´', 'ê¸´ê¸‰', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì§€ê¸ˆ', 'ê²°êµ­', 'ë‰´ìŠ¤', 'ì˜ìƒ', 'ëŒ€ë¶€ë¶„', 'ì´ìœ ', 'ì™œ', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•˜ëŠ”', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ì§„ì§œ', 'ì •ë§', 'ë„ˆë¬´', 'ê·¸ëƒ¥', 'ì´ì œ', 'ì‚¬ì‹¤', 'êµ­ë¯¼', 'ìš°ë¦¬', 'ëŒ€í•œë¯¼êµ­', 'ì—¬ëŸ¬ë¶„', 'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë‚˜', 'ì†”ì§íˆ', 'ë¬´ìŠ¨', 'ì–´ë–¤']
    
    tokens = [normalize_korean_word(w) for w in raw_tokens]
    return [t for t in tokens if t not in noise and len(t) > 1]

def detect_subject_logic(title):
    """ì œëª©ì—ì„œ ì£¼ì–´(Subject) ì¶”ë¡ """
    tokens = extract_meaningful_tokens(title)
    
    # 1. VIP ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­ (ìµœìš°ì„ )
    for vip in VIP_ENTITIES:
        if vip in title: return vip
    
    # 2. í˜¸ì¹­ ê¸°ë°˜ ì¶”ë¡  ("OOO íšŒì¥", "OOO ì”¨")
    honorifics = ['íšŒì¥', 'ì˜ì›', 'ëŒ€í‘œ', 'ëŒ€í†µë ¹', 'ì¥ê´€', 'ë°•ì‚¬', 'êµìˆ˜', 'ê°ë…', 'ì„ ìˆ˜', 'ì”¨', 'ë°°ìš°', 'ê°€ìˆ˜', 'ê°œê·¸ë§¨', 'ë°©ì†¡ì¸']
    title_split = title.split()
    for i, word in enumerate(title_split):
        for hon in honorifics:
            if hon in word and i > 0:
                prev_word = normalize_korean_word(title_split[i-1])
                if len(prev_word) > 1: return prev_word
                
    # 3. ë¬¸ì¥ ë§¨ ì• ëª…ì‚¬ (í™•ë¥  ë†’ìŒ)
    if tokens: return tokens[0]
    return ""

def generate_smart_query(title, transcript):
    """ë‰´ìŠ¤ ê²€ìƒ‰ìš© ìµœì  ì¿¼ë¦¬ ìƒì„±"""
    # 1. ì£¼ì–´ ì°¾ê¸°
    subject = detect_subject_logic(title)
    
    # 2. í•µì‹¬ í–‰ìœ„/ì‚¬ê±´ ì°¾ê¸° (ì œëª©ê³¼ ìë§‰ì˜ êµì§‘í•© ì¤‘ ê°€ì¥ ê¸´ ë‹¨ì–´)
    t_tokens = set(extract_meaningful_tokens(title))
    # ìë§‰ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©í•˜ì—¬ ë¬¸ë§¥ íŒŒì•…
    tr_tokens = set(extract_meaningful_tokens(transcript[:1000]))
    
    common = t_tokens.intersection(tr_tokens)
    # ì£¼ì–´ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ì¤‘ ê°€ì¥ ê¸´ ë‹¨ì–´ (êµ¬ì²´ì  ì‚¬ê±´ì¼ í™•ë¥  ë†’ìŒ)
    actions = [w for w in common if w != subject]
    
    action = max(actions, key=len) if actions else ""
    
    # 3. Fallback: êµì§‘í•©ì´ ì—†ìœ¼ë©´ ì œëª©ì˜ ì¤‘ìš” ë‹¨ì–´ ì‚¬ìš©
    if not action:
        # ì œëª©ì—ì„œ ì¹˜ëª…ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
        for crit in CRITICAL_STATE_KEYWORDS:
            if crit in title:
                action = crit
                break
    
    # 4. ìµœì¢… ì¡°í•©
    if subject and action:
        return f"{subject} {action}"
    elif subject:
        return f"{subject} {title.split()[-1]}" # ì£¼ì–´ + ì œëª© ëë‹¨ì–´
    else:
        return " ".join(extract_meaningful_tokens(title)[:3])

# --- [3. ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ í•¨ìˆ˜] ---
def fetch_real_transcript(info):
    try:
        url = None
        # ìë™ ìë§‰ ìš°ì„  íƒìƒ‰
        for key in ['subtitles', 'automatic_captions']:
            if key in info and 'ko' in info[key]:
                for fmt in info[key]['ko']:
                    if fmt['ext'] == 'vtt': url = fmt['url']; break
            if url: break
            
        if url:
            res = requests.get(url)
            if res.status_code == 200 and "#EXTM3U" not in res.text:
                clean = []
                for line in res.text.splitlines():
                    if '-->' not in line and 'WEBVTT' not in line and line.strip():
                        t = re.sub(r'<[^>]+>', '', line).strip()
                        if t and t not in clean: clean.append(t)
                return " ".join(clean)
    except: pass
    return info.get('description', '')

def fetch_news_regex(query):
    news_res = []
    try:
        # êµ¬ê¸€ ë‰´ìŠ¤ RSS ì‚¬ìš© (ê°€ë³ê³  ë¹ ë¦„)
        rss_url = f"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR&ceid=KR:ko"
        raw = requests.get(rss_url, timeout=5).text
        items = re.findall(r'<item>(.*?)</item>', raw, re.DOTALL)
        
        for item in items[:10]: # ìƒìœ„ 10ê°œ
            t = re.search(r'<title>(.*?)</title>', item)
            d = re.search(r'<description>(.*?)</description>', item) # RSSì—” ì„¤ëª…ì´ ì—†ì„ ìˆ˜ ìˆìŒ
            
            nt = t.group(1).replace("<![CDATA[", "").replace("]]>", "") if t else ""
            nd = clean_html_regex(d.group(1).replace("<![CDATA[", "").replace("]]>", "")) if d else ""
            
            # ì¶œì²˜ ì¶”ì¶œ (ì œëª© ë’¤ ' - ì–¸ë¡ ì‚¬ëª…')
            source = ""
            if " - " in nt:
                parts = nt.rsplit(" - ", 1)
                nt = parts[0]
                source = parts[1]
                
            news_res.append({'title': nt, 'desc': nd, 'source': source})
    except: pass
    return news_res

def clean_html_regex(text):
    return re.sub('<.*?>', '', text).strip()

def calculate_match_score(news_title, query, transcript, video_title):
    # 1. ì¿¼ë¦¬ í‚¤ì›Œë“œ ë§¤ì¹­
    q_tokens = set(extract_meaningful_tokens(query))
    n_tokens = set(extract_meaningful_tokens(news_title))
    
    match_cnt = len(q_tokens & n_tokens)
    base_score = 0
    
    if match_cnt >= 2: base_score = 80
    elif match_cnt == 1: base_score = 40
    
    # 2. Critical Check (ì¹˜ëª…ì  í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜ ì‹œ 0ì )
    # ì˜ˆ: ì˜ìƒì—” 'ì‚¬ë§'ì´ ìˆëŠ”ë° ë‰´ìŠ¤ì—” ì—†ë‹¤? -> 0ì 
    for crit in CRITICAL_STATE_KEYWORDS:
        if crit in video_title and crit not in news_title:
            return 0
            
    return base_score

def summarize_text_simple(text):
    if not text: return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    sents = text.split('.')
    # 3ë¬¸ì¥ë§Œ ì¶”ì¶œ
    return ". ".join([s.strip() for s in sents[:3] if s.strip()]) + "."

def save_analysis_history(channel, title, score, url, query):
    try:
        supabase.table("analysis_history").insert({
            "channel_name": channel,
            "video_title": title,
            "fake_prob": score,
            "analysis_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "video_url": url,
            "keywords": query
        }).execute()
    except: pass

def get_db_stats():
    try:
        res = supabase.table("analysis_history").select("fake_prob").execute()
        if res.data:
            df = pd.DataFrame(res.data)
            return len(df), len(df[df['fake_prob'] < 40]), len(df[df['fake_prob'] > 60]), df
    except: pass
    return 0, 0, 0, pd.DataFrame()

# --- [4. UI ì»´í¬ë„ŒíŠ¸] ---
def render_score_breakdown(items):
    # HTML Tableë¡œ ì ìˆ˜ ë‚´ì—­ ì´ì˜ê²Œ í‘œì‹œ
    rows = ""
    for label, score, note in items:
        color = "#ffcccc" if score > 0 else "#ccffcc" if score < 0 else "#f0f0f0"
        sign = "+" if score > 0 else ""
        rows += f"<tr><td style='padding:8px;'>{label}<br><span style='font-size:0.8em;color:gray'>{note}</span></td><td style='padding:8px;text-align:right;background-color:{color};font-weight:bold'>{sign}{score}</td></tr>"
    
    st.markdown(f"""
    <table style="width:100%; border-collapse:collapse; border:1px solid #ddd; font-size:14px;">
        <thead><tr style="background-color:#f9f9f9;"><th>ë¶„ì„ í•­ëª©</th><th style="text-align:right">ì ìˆ˜</th></tr></thead>
        <tbody>{rows}</tbody>
    </table>
    """, unsafe_allow_html=True)

def witty_loading(step):
    msgs = [
        "ğŸ§  Pure Logic Engine ì´ˆê¸°í™” ì¤‘...",
        "ğŸ“¡ ì˜ìƒ ë°ì´í„° ë° ìë§‰ ì¶”ì¶œ ì¤‘...",
        "ğŸ” ì •êµí•œ íŒ¨í„´ ë§¤ì¹­ ë° íŒ©íŠ¸ êµì°¨ ê²€ì¦ ì¤‘...",
        "âš–ï¸ ìµœì¢… íŒê²°ë¬¸ ì‘ì„± ì¤‘..."
    ]
    with st.status("ğŸ•µï¸ ì •ë°€ ë¶„ì„ ì§„í–‰ ì¤‘...", expanded=True) as status:
        st.write(msgs[step])
        time.sleep(0.5)
        status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

# --- [5. ë©”ì¸ ì•± ì‹¤í–‰] ---
def main():
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ›¡ï¸ ê´€ë¦¬ì")
        if st.session_state.get("is_admin", False):
            st.success("ë¡œê·¸ì¸ë¨")
            if st.button("ë¡œê·¸ì•„ì›ƒ"): st.session_state["is_admin"] = False; st.rerun()
        else:
            with st.form("login"):
                if st.form_submit_button("ë¡œê·¸ì¸"):
                    if st.text_input("PW", type="password") == ADMIN_PASSWORD:
                        st.session_state["is_admin"] = True; st.rerun()
                        
        st.divider()
        db_total, t_cnt, f_cnt, _ = get_db_stats()
        st.metric("ëˆ„ì  ë°ì´í„°", f"{db_total}ê±´")
        st.caption(f"ì§„ì‹¤: {t_cnt} | ê±°ì§“: {f_cnt}")

    st.title("âš–ï¸ Fact-Check Center v54.0")
    st.caption("ğŸš€ Powered by **Pure Logic Engine** (Fast & Stable)")

    url_input = st.text_input("ğŸ”— ë¶„ì„í•  ìœ íŠœë¸Œ URL ì…ë ¥")
    
    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if not url_input:
            st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        witty_loading(0)
        
        # 1. ì˜ìƒ ì •ë³´ ì¶”ì¶œ
        witty_loading(1)
        with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
            try:
                info = ydl.extract_info(url_input, download=False)
                title = info.get('title', '')
                uploader = info.get('uploader', '')
                tags = info.get('tags', [])
                full_text = fetch_real_transcript(info)
            except Exception as e:
                st.error(f"ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return

        # 2. ë¶„ì„ ë¡œì§ ìˆ˜í–‰
        witty_loading(2)
        
        # ì¿¼ë¦¬ ìƒì„±
        query = generate_smart_query(title, full_text)
        
        # ë‰´ìŠ¤ ê²€ìƒ‰
        news_items = fetch_news_regex(query)
        
        # ì¼ì¹˜ë„ ê³„ì‚°
        max_match_score = 0
        verified_news = []
        for item in news_items:
            s = calculate_match_score(item['title'], query, full_text, title)
            if s > max_match_score: max_match_score = s
            verified_news.append({'ë‰´ìŠ¤ ì œëª©': item['title'], 'ì¶œì²˜': item['source'], 'ì¼ì¹˜ë„': f"{s}%"})
            
        # --- ì ìˆ˜ ì‚°ì • (Scoring) ---
        base_score = 50
        details = []
        
        # A. ë‰´ìŠ¤ ê²€ì¦ ì ìˆ˜
        is_silent = (len(news_items) == 0) or (max_match_score < 30)
        has_critical = any(k in title for k in CRITICAL_STATE_KEYWORDS)
        
        news_score = 0
        news_note = ""
        
        if is_silent:
            if has_critical:
                news_score = 5 # ì¤‘ë¦½ì  ê²½ê³ 
                news_note = "âš ï¸ ë¯¸ê²€ì¦ ìœ„í—˜ ì£¼ì¥ (íŒë‹¨ ë³´ë¥˜)"
            else:
                news_score = 10
                news_note = "ì¦ê±° ë¶ˆì¶©ë¶„ (ì¹¨ë¬µ)"
        else:
            if max_match_score >= 80:
                news_score = -45
                news_note = "âœ… ë‰´ìŠ¤ ê²€ì¦ ì™„ë£Œ (íŒ©íŠ¸ ì¼ì¹˜)"
            elif max_match_score >= 40:
                news_score = -20
                news_note = "ë¶€ë¶„ì  ì‚¬ì‹¤ í™•ì¸"
            else:
                news_score = 10
                news_note = "ë‚®ì€ ì—°ê´€ì„±"
                
        details.append(("ë‰´ìŠ¤ êµì°¨ ê²€ì¦", news_score, news_note))
        
        # B. ê³µì‹ ì±„ë„ ë³´ë„ˆìŠ¤
        official_score = 0
        if any(o in uploader for o in OFFICIAL_CHANNELS):
            official_score = -50
            details.append(("ê³µì‹ ì–¸ë¡ ì‚¬", -50, "ì‹ ë¢°ë„ ë³´ì¥"))
            
        # C. ìê·¹ì„± í˜ë„í‹°
        agitation = sum(title.count(w) + full_text.count(w) for w in ['ì¶©ê²©','ê²½ì•…','í­ë¡œ','ì†ë³´','ê¸´ê¸‰'])
        agitation_score = min(agitation * 5, 20)
        if agitation_score > 0:
            details.append(("ìê·¹ì  í‘œí˜„", agitation_score, f"ì„ ë™ í‚¤ì›Œë“œ {agitation}íšŒ"))
            
        # ìµœì¢…
